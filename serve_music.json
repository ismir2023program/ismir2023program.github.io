[
  {
    "abstract": "<b>Confluyo yo, el ambiente me sigue</b> is an extrospective study of the relationships between intentional sounds, autonomous natural sounds, and sounds as byproducts of human activity. This piece integrates human improvisation with artificial intelligence, where an 'unlooper\u2019 generates intricate sonic variations of loose, nine-second themes played by the performer called 'seeds.' Through a generative model, the seeds gradually dematerialize and morph into different sound distributions, which fosters an evolving dialogue between the performer and the co-creative AI, resulting in a continuously changing texture for the performer's improvisation. Drawing from the aesthetics of sonic ecology, the piece emphasizes the complex interconnections between intentional, incidental, and autonomous sounds in our acoustic ecosystem.",
    "affiliation": "Northwestern University",
    "author_emails": "hugofloresgarcia@u.northwestern.edu",
    "authors": "Hugo Flores Garcia",
    "bio": "",
    "channel_name": "",
    "channel_url": "",
    "position": "1",
    "primary_author": "Hugo Flores Garcia",
    "primary_email": "hugofloresgarcia@u.northwestern.edu",
    "release_consent": "",
    "session": "1",
    "thumbnail_link": "",
    "title": "\"confluyo yo, el ambiente me sigue\"",
    "uid": "1",
    "web_link": "https://hugo-does-things.notion.site/confluyo-yo-el-ambiente-me-sigue-38a1b1073a1643a5b2ad0902a02daba7",
    "yt_id": "https://www.youtube.com/embed/mcjf2iKf8Nk?si=9JxMM2CE6JCjWAE_"
  },
  {
    "abstract": "This paper describes a series of real-time music improvisation systems we have created over the last 15 years. The systems are all based on variable-order Markov models. We explain our iterated design process focused on creating collaborative AI systems to enhance human musical experiences. We have used the systems to play piano, drums and even to control a set of live effects and loopers. The systems have performed at live concerts with professional musicians, with some performances being broadcast on national radio. The system is sufficiently well-developed that professional and amateur musicians can now use it in various improvising contexts without our direct support.",
    "affiliation": "Goldsmiths, University of London",
    "author_emails": " m.yee-king@gold.ac.uk | dinverno@gold.ac.uk",
    "authors": " Matthew Yee-King | Mark d'Inverno",
    "bio": "<b>Mark d\u2019Inverno</b> is a critically acclaimed jazz pianist (BBC TV & National Radio, BBC Music Magazine, Guardian, Observer, Jazz Review) who has toured nationally and internationally since the 1980s. He is also a full professor at Goldsmiths, University of London, taking on the role in 2006. He is recognised as a leading academic researcher exploring the relationship between Artificial Intelligence and Human creativity, and his invited talks included improvised piano performances with AI systems. He has over 250 peer-reviewed publications, was formerly Director of Research at Goldsmiths, and currently holds honorary research positions at Instituto de Investigaci\u00f3n en Inteligencia Artificial (IIIA) Universitat Aut\u00f2noma de Barcelona and Politecnico di Milano, Italy. ",
    "channel_name": "",
    "channel_url": "",
    "position": "2",
    "primary_author": "Matthew Yee-King",
    "primary_email": "m.yee-king@gold.ac.uk",
    "release_consent": "",
    "session": "1",
    "thumbnail_link": "",
    "title": "Conversations with our Digital Selves: the development of an autonomous music improviser",
    "uid": "2",
    "web_link": "",
    "yt_id": ""
  },
  {
    "abstract": "We organized a collaborative vocal performance using interaction with an automated piano. The performance was an experiment to see if MIR technology could be used to minimize the number of performers or operators and create a natural performance. The performance was held on June 27 at the KAIST Sports Complex with soprano Sumi Cho, and &lt;Heidenl\u00f6slein (Wild Rose)&gt; was the first of the songs performed. The system consists of 1. an automatic expressive performance generation system virtusonet / 2. a vocal reactive accompaniment system to adjust the timing for virtusonet 3. virtual performer visualization, 4. automatic lyric tracking, and 5. control system.<br/>The piece begins without a piano player, but instead with an automated piano and a visualization of the sides and hands to fill in the presence of the performer. &lt;Heidenl\u00f6slein&gt; has three repeated fermata sections in which the performance system waits for the accompaniment in time with the singing and shows interactions at the right time. In addition, a system specialized in tracking lyrics was used to automatically track and display the lyrics, and the entire system was automated by enabling real-time communication. Despite the wet and noisy environment of the performance hall, the system worked successfully in the actual performance, demonstrating the possibility of systematically applying the technology in the actual performance hall instead of the laboratory.<br/>",
    "affiliation": "",
    "author_emails": "",
    "authors": "",
    "bio": "",
    "channel_name": "",
    "channel_url": "",
    "position": "3",
    "primary_author": "",
    "primary_email": "",
    "release_consent": "",
    "session": "1",
    "thumbnail_link": "",
    "title": "AI Pianist Performance: Collaboration with Soprano Sumi Jo",
    "uid": "3",
    "web_link": "",
    "yt_id": "https://drive.google.com/file/d/1Wx6Kq-PogNSTL6Yv3Tocfvg7ol1FFWZk/view?usp=sharing"
  },
  {
    "abstract": "This submission introduces \"The Words I Tried to Say,\" a multimedia piece created in Adobe Animate that explores the visual representation of music. The project delves into the emotional intricacies of music by incorporating key frames at significant musical points and complementing them with expressive lines, evoking a sense of directionless wandering in darkness. Each key frame captures the essence of the music at precise moments, forming a profound visual narrative that mirrors the ebb and flow of emotions within the composition. By skillfully interconnecting these key frames using the Adobe Animate transform tool, the project crafts a seamless and immersive experience, enabling viewers to delve deeper into the interconnected relationship between music and visuals. \"The Words I Tried to Say\" offers a captivating and thought-provoking exploration of the expressive potential of music through digital art, paving the way for innovative approaches in the realm of multimedia storytelling.",
    "affiliation": "University of Glasgow",
    "author_emails": "2485186N@student.gla.ac.uk",
    "authors": "Angela Weihan Ng",
    "bio": "",
    "channel_name": "",
    "channel_url": "",
    "position": "4",
    "primary_author": "Angela Weihan Ng",
    "primary_email": "2485186N@student.gla.ac.uk",
    "release_consent": "",
    "session": "1",
    "thumbnail_link": "",
    "title": "The Words I Tried to Say ",
    "uid": "4",
    "web_link": "",
    "yt_id": "https://youtu.be/xF_EpFz8SAg"
  },
  {
    "abstract": "This proposal presents the performance of an original piece inspired by the Irish folk tradition. The HITar, an augmented guitar prototype for percussive fingerstyle, is used here to imitate the sound of the bodhr\u00e1n, an Irish frame drum, while improvising over the theme of a jig.",
    "affiliation": "Queen Mary University of London",
    "author_emails": "a.martelloni@qmul.ac.uk | a.mcpherson@qmul.ac.uk | m.barthet@qmul.ac.uk",
    "authors": "Andrea Martelloni | Andrew McPherson | Mathieu Barthet",
    "bio": "<b>Andrea Martelloni</b> is a guitar player, composer, producer and fourth-year PhD student at the Artificial Intelligence and Music programme at C4DM, Queen . His research includes work on the HITar and the field of gesture recognition applied to expressive digital musical instruments, as well as behavioural methods to evaluate DMIs such as micro-phenomenology. He has being playing guitar for over twenty years, studying at the Centro Professione Musica in Milan during his teenage and carrying on as self-taught afterwards. He is an active session musician in the South East of England. His current main project is Sloth In The City with wife and saxophonist Betty Accorsi. Other projects include solo guitar act Virgult, jazz guitar (Betty Accorsi Quartet, Madz and the Martians), function (Miss and the Demeanors), folk (Monkey See Monkey Do, Hilltop Ceilidh Band).<br><br><b>Mathieu Barthet</b> (PhD) is a senior lecturer at Queen Mary University of London and guitarist/composer. He received MSc degrees in electronics and computer science (Paris VI University, 2003) and acoustics (Aix-Marseille University/Ecole Centrale Marseille, 2004). He was awarded a PhD in acoustics, signal processing, and computer science applied to music (Aix-Marseille University/CNRS-LMA, 2008). He holds a professional certificate in music theory and composition (Berklee Online). He is the director of the UKRI Media & Arts Technology Centre for Doctoral Training (CDT), and co-investigator on the UKRI AI & Music CDT. He co-authored over 130 publications on new interfaces for musical expression, music information retrieval, and music perception.",
    "channel_name": "",
    "channel_url": "",
    "position": "5",
    "primary_author": "Andrea Martelloni",
    "primary_email": "a.martelloni@qmul.ac.uk",
    "release_consent": "",
    "session": "1",
    "thumbnail_link": "",
    "title": "Sliog\u00e1n: a performance composed for the HITar ",
    "uid": "5",
    "web_link": "",
    "yt_id": "https://www.youtube.com/watch?v=64JVrCn5ih8"
  },
  {
    "abstract": "Nor Hope is a piece for soprano, electronics, and video that I wrote in the summer of 2021. The music was inspired by William Butler Yeats's poem \"Death.\" The vocalist sings a melody without words, showcasing the radiant high register of the soprano's voice. Most of the electronic sounds in the piece are generated and processed by programming software. I used the electronics to create a tranquil soundscape that fits the mood of the poem.<br/><br/>In order to present the music at a digital concert during the pandemic, I created a music video that features soprano Stephany Svorini\u0107 performing in Salem. The video editing process allowed me to create a visual experience that enhanced the audience's engagement with the music.",
    "affiliation": "",
    "author_emails": "lwb862413031@gmail.com",
    "authors": "Wenbin Lyu",
    "bio": "<b>Wenbin Lyu</b> is a Chinese composer based in Cincinnati. His compositions blend contemporary Western techniques with ancient Oriental culture, drawing inspiration from nature, science, and video games. His works have been featured at over 60 music festivals, such as Cabrillo, Tanglewood, NYCEMF, IRCAM, SEAMUS, and ICMC. He has collaborated with acclaimed ensembles, including the Buffalo Philharmonic, Albany Symphony, Beijing Symphony, Eighth Blackbird, Akropolis Quintet, and Sandbox Percussion. Lyu has received one ASCAP Young Composer Award and three The American Prize awards. He holds degrees from the China Conservatory, NEC, and CCM.",
    "channel_name": "",
    "channel_url": "",
    "position": "6",
    "primary_author": "Wenbin Lyu",
    "primary_email": "lwb862413031@gmail.com",
    "release_consent": "",
    "session": "1",
    "thumbnail_link": "",
    "title": "Nor Hope",
    "uid": "6",
    "web_link": "https://wenbinlyu.com",
    "yt_id": "https://drive.google.com/file/d/18JWj-NIC8l2Jc5N2jv5jBvN0GuiAahO4/view"
  }
]
