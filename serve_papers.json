[
  {
    "AwardNominee": "True",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1DvOBLNNh3C8wfID8ClLVXxXqj2suDBzO/view?",
    "abstract": "Musicology research suggests a correspondence between manual gesture and melodic contour in raga performance. Computational tools such as pose estimation from video and time series pattern matching potentially facilitate larger-scale studies of gesture an",
    "abstract_short": "",
    "author_emails": "shreyasnadkarni@ee.iitb.ac.in; 214077004@iitb.ac.in; prao@ee.iitb.ac.in; martin.clayton@durham.ac.uk",
    "authors_and_affil": "Shreyas M Nadkarni (Indian Institute of Technology Bombay); Sujoy Roychowdhury (Indian Institute of Technology Bombay); Preeti Rao (Indian Institute of Technology  Bombay)*; Martin Clayton (Durham University)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "True",
    "paper_presentation": "In Person",
    "pdf_name": "000001.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000001.pdf",
    "position": "0",
    "poster_pdf": "https://drive.google.com/file/d/1SJX_IvazSTMMezLbKk_2kT-4g3_pSFev/view",
    "primary_author": "Preeti Rao",
    "primary_email": "prao@ee.iitb.ac.in",
    "primary_subject": "Knowledge-driven approaches to MIR -> computational ethnomusicology",
    "proceedings_id": "1",
    "secondary_subject": "MIR fundamentals and methodology -> multimodality",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1wUQl2ZIp4gBwMCCxHAWl2PAOKeLfN5qs/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1GlniwEHuaE5n0Zei7oXLyVn_dHGy0bmm/view?usp=sharing",
    "title": "Exploring the correspondence of melodic contour with gesture in raga alap singing ",
    "uid": "64",
    "video": "https://drive.google.com/uc?export=view&id=1DvOBLNNh3C8wfID8ClLVXxXqj2suDBzO"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1yFCCW_X06c_V-Q_xlfOnCbM8JoNzIVtu/view",
    "abstract": "Thanks to advancements in deep learning (DL), automatic music transcription (AMT) systems recently outperformed previous ones fully based on manual feature design. Many of these highly capable DL models, however, are computationally expensive. Researchers",
    "abstract_short": "",
    "author_emails": "miguel_on_94@hotmail.com; holger.kirchhoff@huawei.com; xavier.serra@upf.edu",
    "authors_and_affil": "Miguel Perez Fernandez (Universitat Pompeu Fabra; Huawei)*; Holger Kirchhoff (Huawei); Xavier Serra (Universitat Pompeu Fabra )",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000002.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000002.pdf",
    "position": "1",
    "poster_pdf": "https://drive.google.com/file/d/14jgsYz5Nb8m3OGaiW4RxQe26yi35tyhL/view",
    "primary_author": "Miguel Perez Fernandez",
    "primary_email": "miguel_on_94@hotmail.com",
    "primary_subject": "MIR tasks -> music transcription and annotation",
    "proceedings_id": "2",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Knowledge-driven approaches to MIR -> representations of music; MIR fundamentals and methodology -> music signal processing; MIR tasks -> pattern matching and detection; Musical features and properties -> representations of music",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1Mmrf4Umxtbn_To-nnkTw8tkcrspuyYCP/view",
    "thumbnail": "https://drive.google.com/file/d/1juo5XqKdMdu8902Kq6GWZ2BOAE1wCFw4/view",
    "title": "TriAD: Capturing harmonics with 3D Convolutions",
    "uid": "11",
    "video": "https://drive.google.com/uc?export=view&id=1yFCCW_X06c_V-Q_xlfOnCbM8JoNzIVtu"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1-QENG5zYQSGwLoG9VowxWCQ2p9GqEKf5/view",
    "abstract": "The practices of data collection in training sets for Automatic Music Generation (AMG) tasks are opaque and overlooked. In this paper, we aimed to identify these practices and surface the values they embed. We systematically identified all datasets used t",
    "abstract_short": "",
    "author_emails": "f.morreale@auckland.ac.nz; meghas@g.ecc.u-tokyo.ac.jp; iwei022@aucklanduni.ac.nz",
    "authors_and_affil": "Fabio Morreale (University of Auckland)*; Megha Sharma (University of Tokyo); I-Chieh Wei (University of Auckland)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000003.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000003.pdf",
    "position": "2",
    "poster_pdf": "https://drive.google.com/file/d/1UqLBTjYlhPcuEpl676ybWk9Nq0kGb9H8/view",
    "primary_author": "Fabio Morreale",
    "primary_email": "f.morreale@auckland.ac.nz",
    "primary_subject": "Philosophical and ethical discussions -> ethical issues related to designing and implementing MIR tools and technologies",
    "proceedings_id": "3",
    "secondary_subject": "MIR tasks -> music generation; Philosophical and ethical discussions -> legal and societal aspects of MIR",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1RVWV_3soKGbFOVUz1Q05avA5IMlyw5D-/view?usp=sharing ",
    "thumbnail": "https://drive.google.com/file/d/1LO7bnd58OVp9yfX6fId8yV5tJF-rIk68/view",
    "title": "Data Collection in Music Generation Training Sets: A Critical Analysis",
    "uid": "15",
    "video": "https://drive.google.com/uc?export=view&id=1-QENG5zYQSGwLoG9VowxWCQ2p9GqEKf5"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1gr803BCvb98rdFiAzIpGivrGkgEtNkt-/view",
    "abstract": "Validity is the truth of an inference made from evidence and is a central concern in scientific work. Given the maturity of the domain of music information research (MIR), validity in our opinion should be discussed and considered much more than it has be",
    "abstract_short": "",
    "author_emails": "bobs@kth.se; arthur.flexer@jku.at",
    "authors_and_affil": "Bob L. T.  Sturm (KTH Royal Institute of Technology); Arthur Flexer (Johannes Kepler University Linz)*",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000004.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000004.pdf",
    "position": "3",
    "poster_pdf": "https://drive.google.com/file/d/1J9FH9FKTPCGRiRyCMbB_23NdfKI-7JW8/view",
    "primary_author": "Arthur Flexer",
    "primary_email": "arthur.flexer@jku.at",
    "primary_subject": "Philosophical and ethical discussions",
    "proceedings_id": "4",
    "secondary_subject": "Evaluation, datasets, and reproducibility; Evaluation, datasets, and reproducibility -> evaluation methodology; Philosophical and ethical discussions -> philosophical and methodological foundations",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1J1lu0SYRpuZW4E7rTZ_a4BL30f8VdaMC/view?usp=share_link",
    "thumbnail": "https://drive.google.com/file/d/1LV47ziqlkzs6AtO4SW_7iPcVeUW8BRO6/view",
    "title": "A Review of Validity and its Relationship to Music Information Research",
    "uid": "18",
    "video": "https://drive.google.com/uc?export=view&id=1gr803BCvb98rdFiAzIpGivrGkgEtNkt-"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1u1UzWleSWCC83KIgrl-JyiHyVkfqVDd6/view",
    "abstract": "In Carnatic music concerts, taniavartanam is a solo percussion segment that showcases intricate and elaborate extempore rhythmic evolution through a series of homogeneous sections with shared rhythmic characteristics. While taniavartanam segments have bee",
    "abstract_short": "",
    "author_emails": "ee19d702@smail.iitm.ac.in; srikrishnansridharan@gmail.com; aravind@ee.iitm.ac.in; hema@cse.iitm.ac.in",
    "authors_and_affil": "Gowriprasad R (IIT Madras)*; Srikrishnan Sridharan (Carnatic Percussionist); R Aravind (Indian Institute of Technology Madras); Hema A Murthy (IIT Madras)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000005.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000005.pdf",
    "position": "4",
    "poster_pdf": "https://drive.google.com/file/d/1_GZqiSYYzUFfLsvr2L8qPjzZYFQF9Iei/view",
    "primary_author": "Gowriprasad R",
    "primary_email": "ee19d702@smail.iitm.ac.in",
    "primary_subject": "Musical features and properties -> structure, segmentation, and form",
    "proceedings_id": "5",
    "secondary_subject": "Applications -> music retrieval systems",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1kOIYVsnr__hCGj3mTg3EkhAJsrTqzsWy/view",
    "thumbnail": "https://drive.google.com/file/d/1HvjtFZBzPh8_T1ICDvb7yBk3BK6mfBv6/view",
    "title": "Segmentation and Analysis of Taniavartanam in Carnatic Music Concerts",
    "uid": "19",
    "video": "https://drive.google.com/uc?export=view&id=1u1UzWleSWCC83KIgrl-JyiHyVkfqVDd6"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1QsT16gA_H-9jCpNLm_lV2flwRr7H_NY8/view?usp=share_link",
    "abstract": "Deep neural network models have become the dominant approach to a large variety of tasks within music information retrieval (MIR). These models generally require large amounts of (annotated) training data to achieve high accuracy. Because not all applicat",
    "abstract_short": "",
    "author_emails": "changhong.wang@telecom-paris.fr; gael.richard@telecom-paris.fr; brian.mcfee@nyu.edu",
    "authors_and_affil": "Changhong Wang (Telecom Paris, Institut polytechnique de Paris)*; Ga\u00ebl Richard (Telecom Paris, Institut polytechnique de Paris); Brian McFee (New York University)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000006.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000006.pdf",
    "position": "5",
    "poster_pdf": "https://drive.google.com/file/d/1xSh8IkEE4LD6SYbg-TwJfMFSNYPX4s1G/view?usp=sharing",
    "primary_author": "Changhong Wang",
    "primary_email": "changhong.wang@telecom-paris.fr",
    "primary_subject": "Musical features and properties -> timbre, instrumentation, and singing voice",
    "proceedings_id": "6",
    "secondary_subject": "Applications -> music retrieval systems; Knowledge-driven approaches to MIR -> representations of music; MIR fundamentals and methodology -> music signal processing; MIR tasks -> automatic classification; Philosophical and ethical discussions -> philosophical and methodological foundations",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1kUiuzoPCa2uZIVgCoK0aIq1871Lqc8lK/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1CX9JLGWqc1qrqyLtjHC5hA85qiBjqvYG/view?usp=share_link",
    "title": "Transfer Learning and Bias Correction with Pre-trained Audio Embeddings",
    "uid": "280",
    "video": "https://drive.google.com/uc?export=view&id=1QsT16gA_H-9jCpNLm_lV2flwRr7H_NY8"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1GFvSckyxGyvPrMzXF7m5K-aq-4ov5sAn/view",
    "abstract": "The Collaborative Song Dataset (CoSoD) is a corpus of 331 multi-artist collaborations from the 2010\u20132019 Billboard \u201cHot 100\u201d year-end charts. The corpus is annotated with formal sections, aspects of vocal production (including reverberation, layering, pan",
    "abstract_short": "",
    "author_emails": "mduguay@fas.harvard.edu; kmancey@g.harvard.edu; johanna.devaney@brooklyn.cuny.edu",
    "authors_and_affil": "Mich\u00e8le Duguay (Harvard University)*; Kate Mancey (Harvard University); Johanna Devaney (Brooklyn College)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000007.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000007.pdf",
    "position": "6",
    "poster_pdf": "https://drive.google.com/file/d/1OGexuCofkntBg7wsXCBzB1KLrT30cDXs/view",
    "primary_author": "Mich\u00e8le Duguay",
    "primary_email": "mduguay@fas.harvard.edu",
    "primary_subject": "Musical features and properties -> timbre, instrumentation, and singing voice",
    "proceedings_id": "7",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1ad-yWmMHEz--xu2_O9x5tVGeDvnn41tU/view",
    "thumbnail": "https://drive.google.com/file/d/15hqeiDppOtjRo2idW-bo4NYiSJMlMXLK/view",
    "title": "Collaborative Song Dataset (CoSoD): An annotated dataset of multi-artist collaborations in popular music",
    "uid": "37",
    "video": "https://drive.google.com/uc?export=view&id=1GFvSckyxGyvPrMzXF7m5K-aq-4ov5sAn"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/12ZEKkCsiIM7gYj_Qkrc5ol0FGDtKb9EX/view",
    "abstract": "Recently, there has been a surge in Artificial Intelligence (AI) tools that allow creators to develop melodies, harmonies, lyrics, and mixes with the touch of a button. The reception of and discussion on the use of these tools - and more broadly, any AI-b",
    "abstract_short": "",
    "author_emails": "mmn13@uw.edu; ljmorris@uw.edu; jinhalee@uw.edu",
    "authors_and_affil": "Michele Newman (University of Washington)*; Lidia J Morris (University of Washington); Jin Ha Lee (University of Washington)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000008.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000008.pdf",
    "position": "7",
    "poster_pdf": "https://drive.google.com/file/d/1lTcgeRKggJmoOSX44-Sg1GrrZ2lurfl6/view",
    "primary_author": "Michele Newman",
    "primary_email": "mmn13@uw.edu",
    "primary_subject": "Human-centered MIR -> human-computer interaction",
    "proceedings_id": "8",
    "secondary_subject": "Applications -> music composition, performance, and production; MIR tasks -> music generation; Philosophical and ethical discussions -> ethical issues related to designing and implementing MIR tools and technologies",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1WxtwM1fg3o6M-QBJvwQzsK3QRx28TAos/view",
    "thumbnail": "https://drive.google.com/file/d/1sOy7sZgpwlBoD_QHqYP9APDTRvUqi9cw/view",
    "title": "Human-AI  Music Creation: Understanding the Perceptions and Experiences of Music Creators for Ethical and Productive Collaboration",
    "uid": "58",
    "video": "https://drive.google.com/uc?export=view&id=12ZEKkCsiIM7gYj_Qkrc5ol0FGDtKb9EX"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/19mvoQ2eSKYbbUn2HbRVjW-8Vimnb6nBh/view",
    "abstract": "Symbolic music is widely used in various deep learning tasks, including generation, transcription, synthesis, and Music Information Retrieval (MIR). It is mostly employed with discrete models like Transformers, which require music to be tokenized, i.e., f",
    "abstract_short": "",
    "author_emails": "nathan.fradet@lip6.fr; nicolas.gutowski@univ-angers.fr; fabien.chhel@eseo.fr; Jean-Pierre.Briot@lip6.fr",
    "authors_and_affil": "Nathan Fradet (LIP6 - Sorbonne University)*; Nicolas Gutowski (University of Angers); Fabien Chhel (Groupe ESEO); Jean-Pierre Briot (CNRS)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000009.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000009.pdf",
    "position": "8",
    "poster_pdf": "https://drive.google.com/file/d/1t-Odohpt7ZGzGBqbGGJVmXYJtgHfDpY8/view",
    "primary_author": "Nathan Fradet",
    "primary_email": "nathan.fradet@lip6.fr",
    "primary_subject": "MIR fundamentals and methodology -> symbolic music processing",
    "proceedings_id": "9",
    "secondary_subject": "Applications -> music composition, performance, and production; Applications -> music retrieval systems; MIR tasks -> automatic classification; MIR tasks -> music generation; Musical features and properties -> representations of music",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1BtSnnUimfGL5ul_FcvyeIDL0Ah7InzkA/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1AaS2ikOX0wJ7eMYB15eQnRr8whwSmgA2/view",
    "title": "Impact of time and note duration tokenizations on deep learning symbolic music modeling",
    "uid": "45",
    "video": "https://drive.google.com/uc?export=view&id=19mvoQ2eSKYbbUn2HbRVjW-8Vimnb6nBh"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/13IupDzqB5wZ13ihRCwvW2X4eY_0VKSww/view",
    "abstract": "Micro-timing is an essential part of human music-making, yet it is absent from most computer music systems. Partly to address this gap, we present a novel system for generating music with style-specific micro-timing within the Sonic Pi live coding languag",
    "abstract_short": "",
    "author_emails": "mj551@cantab.ac.uk; mark.r.gotham@durham.ac.uk",
    "authors_and_affil": "Max Johnson (University of Cambridge); Mark R H Gotham (Durham)*",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000010.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000010.pdf",
    "position": "9",
    "poster_pdf": "https://drive.google.com/file/d/1Ce-lVzeVmR8ZewQV4t9vv0KOzCr-VUDA/view",
    "primary_author": "Mark R H Gotham",
    "primary_email": "mark.r.gotham@durham.ac.uk",
    "primary_subject": "Applications -> music composition, performance, and production",
    "proceedings_id": "10",
    "secondary_subject": "Computational musicology -> mathematical music theory; Human-centered MIR -> human-computer interaction; MIR fundamentals and methodology -> symbolic music processing; Musical features and properties -> rhythm, beat, tempo",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1h6_WqB13JtLM0GSw2nZBJq3r_CeSN1ln/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1_wE0HU7LTpsi57jFw47FQTcQQjYCxXJb/view",
    "title": "Musical Micro-Timing for Live Coding",
    "uid": "93",
    "video": "https://drive.google.com/uc?export=view&id=13IupDzqB5wZ13ihRCwvW2X4eY_0VKSww"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Yk4OZSK1v7reHk99gfC_SD_i-MkAk9DZ/view",
    "abstract": "Optical Music Recognition (OMR) is a well-established research field focused on the task of reading musical notation from images of music scores. In the standard OMR workflow, layout analysis is a critical component for identifying relevant parts of the i",
    "abstract_short": "",
    "author_emails": "fcastellanos@dlsi.ua.es; jgallego@dlsi.ua.es; ichiro.fujinaga@mcgill.ca",
    "authors_and_affil": "Francisco J. Castellanos (University of Alicante)*; Antonio Javier Gallego (Universidad de Alicante); Ichiro Fujinaga (McGill University)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000011.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000011.pdf",
    "position": "10",
    "poster_pdf": "https://drive.google.com/file/d/1_bVna_LTgc60q8uVuiVBzoM65a1qtWdg/view",
    "primary_author": "Francisco J. Castellanos",
    "primary_email": "fcastellanos@dlsi.ua.es",
    "primary_subject": "MIR tasks -> optical music recognition",
    "proceedings_id": "11",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1zKoF02N2rR5QIyWXaGT2sF-NnTF_KpqS/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1n06Hd9Os7bmpYO9lGfmABVz7nz7LEFnK/view",
    "title": "A Few-shot Neural Approach for Layout Analysis of Music Score Images",
    "uid": "47",
    "video": "https://drive.google.com/uc?export=view&id=1Yk4OZSK1v7reHk99gfC_SD_i-MkAk9DZ"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1XuSgxSZWStQ-ojpQ88Zs_ZJ1ZqQbtAf7/view",
    "abstract": "Drummers spend extensive time practicing rudiments to develop technique, speed, coordination, and phrasing. These rudiments are often practiced on \"silent\" practice pads using only the hands. Additionally, many percussive instruments across cultures are p",
    "abstract_short": "",
    "author_emails": "behzad.haki@upf.edu; kotowski.blazej@gmail.com; clilee@connect.ust.hk; sergi.jorda@upf.edu",
    "authors_and_affil": "Behzad Haki (Universitat Pompeu Fabra)*; B_a_ej Kotowski (MTG); Cheuk Lun Isaac Lee (Universitat Pompeu Fabra ); Sergi Jord\u00e0 (Universitat Pompeu Fabra)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000012.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000012.pdf",
    "position": "11",
    "poster_pdf": "https://drive.google.com/file/d/1riEMHjWzUeSl6UDSchFFDwMUa5vLn55O/view",
    "primary_author": "Behzad Haki",
    "primary_email": "behzad.haki@upf.edu",
    "primary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "proceedings_id": "12",
    "secondary_subject": "Musical features and properties -> representations of music; Musical features and properties -> rhythm, beat, tempo",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1VzVmgua7PcBoZzsVC2ZRNbg4Icj3kK9Q/view",
    "thumbnail": "https://drive.google.com/file/d/1HrcaIZ5sVn1gMcPy2ZLP1QRF0wD1a9A2/view",
    "title": "TapTamDrum: A Dataset for Dualized Drum Patterns",
    "uid": "33",
    "video": "https://drive.google.com/uc?export=view&id=1XuSgxSZWStQ-ojpQ88Zs_ZJ1ZqQbtAf7"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1nr-HTFvdiIC2X5TbKLGL3ri8vZr_npdO/view?usp=sharing ",
    "abstract": "Real-time music information retrieval (RT-MIR) has much potential to augment the capabilities of traditional acoustic instruments. We develop RT-MIR techniques aimed at augmenting percussive fingerstyle, which blends acoustic guitar playing with guitar bo",
    "abstract_short": "",
    "author_emails": "a.martelloni@qmul.ac.uk; a.mcpherson@qmul.ac.uk; m.barthet@qmul.ac.uk",
    "authors_and_affil": "Andrea Martelloni (Queen Mary University of London)*; Andrew McPherson (QMUL); Mathieu Barthet (Queen Mary University of London)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000013.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000013.pdf",
    "position": "12",
    "poster_pdf": "https://drive.google.com/file/d/1Ergs4Ua6t4qmQvxxNk3auyatJkzI4HEn/view?usp=sharing ",
    "primary_author": "Andrea Martelloni",
    "primary_email": "a.martelloni@qmul.ac.uk",
    "primary_subject": "Applications -> music composition, performance, and production",
    "proceedings_id": "13",
    "secondary_subject": "Human-centered MIR -> human-computer interaction; Human-centered MIR -> music interfaces and services; MIR fundamentals and methodology -> music signal processing; MIR tasks -> automatic classification",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1hOx2myUhk_H6u9r9CP4WHomRkEj3EtV2/view?usp=sharing ",
    "thumbnail": "https://drive.google.com/file/d/1tvccEB0fozHYq3Mk_sf9jfX99sNeAH3o/view?usp=sharing ",
    "title": "Real-time Percussive Technique Recognition and Embedding Learning for the Acoustic Guitar",
    "uid": "48",
    "video": "https://drive.google.com/uc?export=view&id=1nr-HTFvdiIC2X5TbKLGL3ri8vZr_npdO"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1cHkxzOuNBuD0Oc2L2lCZ_wy-gvfdp9hH/view",
    "abstract": "Recent text-to-audio generation techniques have the potential to allow novice users to freely generate music audio. Even if they do not have musical knowledge, such as about chord progressions and instruments, users can try various text prompts to generat",
    "abstract_short": "",
    "author_emails": "hiromu1996@gmail.com; m.goto@aist.go.jp",
    "authors_and_affil": "Hiromu Yakura (University of Tsukuba)*; Masataka Goto (National Institute of Advanced Industrial Science and Technology (AIST))",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000014.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000014.pdf",
    "position": "13",
    "poster_pdf": "https://drive.google.com/file/d/14DnHS_JotLJtFvUB75FB358BSX02a6kf/view",
    "primary_author": "Hiromu Yakura",
    "primary_email": "hiromu1996@gmail.com",
    "primary_subject": "Human-centered MIR -> human-computer interaction",
    "proceedings_id": "14",
    "secondary_subject": "Applications -> music composition, performance, and production; Human-centered MIR -> music interfaces and services; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1y3RfHFBj8ikT1eGcI-Fk40Hhw-Z09Rnf/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1Gxv25ON-lumZ4g95_AA97sD4RESUovos/view",
    "title": "IteraTTA: An interface for exploring both text prompts and audio priors in generating music with text-to-audio models",
    "uid": "80",
    "video": "https://drive.google.com/uc?export=view&id=1cHkxzOuNBuD0Oc2L2lCZ_wy-gvfdp9hH"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1DzQBvv4ftbSQDl1R0T7jL6U53ghxGgax/view?usp=share_link",
    "abstract": "The directivity of a musical instrument is a function that describes the spatial characteristics of its sound radiation. The majority of the available literature focuses on measuring directivity patterns, with analysis mainly limited to visual inspections",
    "abstract_short": "",
    "author_emails": "mirco.pezzoli@polimi.it; raffaele.malvermi@polimi.it; fabio.antonacci@polimi.it; augusto.sarti@polimi.it",
    "authors_and_affil": "Mirco Pezzoli (Politecnicno di Milano)*; Raffaele Malvermi (Politecnico di Milano); Fabio Antonacci (Politecnico di Milano); Augusto Sarti (Politecnico di Milano)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000015.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000015.pdf",
    "position": "14",
    "poster_pdf": "https://drive.google.com/file/d/1ky9p0XdOSPFVcj4bJBtp-KfoHcYF7g01/view?usp=share_link",
    "primary_author": "Mirco Pezzoli",
    "primary_email": "mirco.pezzoli@polimi.it",
    "primary_subject": "MIR and machine learning for musical acoustics",
    "proceedings_id": "15",
    "secondary_subject": "MIR and machine learning for musical acoustics -> applications of musical acoustics to signal synthesis; MIR tasks -> pattern matching and detection; MIR tasks -> similarity metrics",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1PR2B1z0Po2w0caRcljD0QwDimTJQ_Nzg/view",
    "thumbnail": "https://drive.google.com/file/d/1H_OImxj9fVzhHXVarGyY8QDqvp-HbeU_/view",
    "title": "Similarity evaluation of violin directivity patterns for musical instrument retrieval",
    "uid": "174",
    "video": "https://drive.google.com/uc?export=view&id=1DzQBvv4ftbSQDl1R0T7jL6U53ghxGgax"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "",
    "abstract": "Computational models and analyses of musical rhythms are predominantly based on the subdivision of durations down to a common isochronous pulse, which plays a fundamental structural role in the organization of their durational patterns. Meter, the most wi",
    "abstract_short": "",
    "author_emails": "georgios.sioros@plymouth.ac.uk",
    "authors_and_affil": "George Sioros (University of Plymouth)*",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000016.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000016.pdf",
    "position": "15",
    "poster_pdf": "",
    "primary_author": "George Sioros",
    "primary_email": "georgios.sioros@plymouth.ac.uk",
    "primary_subject": "Musical features and properties -> rhythm, beat, tempo",
    "proceedings_id": "16",
    "secondary_subject": "Computational musicology; Computational musicology -> mathematical music theory; MIR fundamentals and methodology -> music signal processing; MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> music generation",
    "session": "1",
    "slack_channel": "",
    "slides_pdf": "",
    "thumbnail": "",
    "title": "Polyrhythmic modelling of non-isochronous and microtiming patterns",
    "uid": "82",
    "video": ""
  },
  {
    "AwardNominee": "True",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1wxx0BrnXEJSS5fFApirGRz1ZjZ4jFfNG/view",
    "abstract": "We introduce CLaMP: Contrastive Language-Music Pre-training, which learns cross-modal representations between natural language and symbolic music using a music encoder and a text encoder trained jointly with a contrastive loss. To pre-train CLaMP, we coll",
    "abstract_short": "",
    "author_emails": "shangda@mail.ccom.edu.cn; yudingyao@pku.edu.cn; xuta@microsoft.com; sms@tsinghua.edu.cn",
    "authors_and_affil": "Shangda Wu (Central Conservatory of Music); Dingyao Yu (Peking University); Xu Tan (Microsoft Research Asia); Maosong Sun (Tsinghua University)*",
    "channel_url": "",
    "day": "2",
    "long_presentation": "True",
    "paper_presentation": "In Person",
    "pdf_name": "000017.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000017.pdf",
    "position": "0",
    "poster_pdf": "https://drive.google.com/file/d/1splCZQofFRIUpAVjijY7oNyIwKrzk8Ao/view?usp=sharing",
    "primary_author": "Maosong Sun",
    "primary_email": "sms@tsinghua.edu.cn",
    "primary_subject": "Applications -> music retrieval systems",
    "proceedings_id": "17",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases; MIR fundamentals and methodology -> multimodality; MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> automatic classification; MIR tasks -> indexing and querying",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1_utPVBoTcFC6oAIl02bIwMDQjo5on6vu/edit?usp=sharing&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1EK8OjR8ufm8Kte0qn8N2mgZShn-3ln7X/view?usp=sharing",
    "title": "CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval",
    "uid": "91",
    "video": "https://drive.google.com/uc?export=view&id=1wxx0BrnXEJSS5fFApirGRz1ZjZ4jFfNG"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/14XBWlSHxm8Z6cDKguzHtyqobvyS5xmTc/view",
    "abstract": "Music can convey ideological stances, and gender is just one of them. Evidence from musicology and psychology research shows that gender-loaded messages can be reliably encoded and decoded via musical sounds. However, much of this evidence comes from exam",
    "abstract_short": "",
    "author_emails": "l.marinelli@qmul.ac.uk; george.fazekas@qmul.ac.uk; c.saitis@qmul.ac.uk",
    "authors_and_affil": "Luca Marinelli (Queen Mary University of London)*; George Fazekas (QMUL); Charalampos Saitis (Queen Mary University of London)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000018.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000018.pdf",
    "position": "1",
    "poster_pdf": "https://drive.google.com/file/d/14oC82QCZKHcnJYoG7X0PicHaE_iNhrSv/view",
    "primary_author": "Luca Marinelli",
    "primary_email": "l.marinelli@qmul.ac.uk",
    "primary_subject": "Knowledge-driven approaches to MIR -> computational music theory and musicology",
    "proceedings_id": "18",
    "secondary_subject": "Applications -> business and marketing; Evaluation, datasets, and reproducibility -> novel datasets and use cases; MIR tasks -> automatic classification; Musical features and properties -> musical affect, emotion and mood",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1W0kjovJhcsT5tCfxr8mvI0mM0RLmg5C0/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1t0t9U2ApBUsYYGC_vorbh7E5bpWql_jk/view",
    "title": "GENDER-CODED SOUND: ANALYSING THE GENDERING OF MUSIC IN TOY COMMERCIALS VIA MULTI-TASK LEARNING",
    "uid": "238",
    "video": "https://drive.google.com/uc?export=view&id=14XBWlSHxm8Z6cDKguzHtyqobvyS5xmTc"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1sx0VLxNPVR2yhVcF7oafzlE4dwxFYw11/view?usp=sharing",
    "abstract": "Nowadays, humans are constantly exposed to music, whether through voluntary streaming services or incidental encounters during commercial breaks. Despite the abundance of music, certain pieces remain more memorable and often gain greater popularity. Inspi",
    "abstract_short": "",
    "author_emails": "liyangtseng.ee10@nycu.edu.tw; jolinkiion5629@gmail.com; hhshuai@nctu.edu.tw; admsd.ee10@nycu.edu.tw; wwchang@nctu.edu.tw",
    "authors_and_affil": "Li-Yang Tseng (National Yang Ming Chiao Tung University); Tzu-Ling Lin (National Yang Ming Chiao Tung University); Hong-Han Shuai (National Yang Ming Chiao Tung University)*; JEN-WEI HUANG (NYCU); Wen-Whei Chang (National Yang Ming Chiao Tung University)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "Virtually",
    "pdf_name": "000019.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000019.pdf",
    "position": "2",
    "poster_pdf": "https://drive.google.com/file/d/1_57q-qGsRO9druNfRi3YHndX4LqLll4r/view",
    "primary_author": "Hong-Han Shuai",
    "primary_email": "hhshuai@nctu.edu.tw",
    "primary_subject": "MIR and machine learning for musical acoustics -> applications of machine learning to musical acoustics",
    "proceedings_id": "19",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1itkdJM23n1dktth-X1wQE_umX3YzhRE2/view?usp=share_link",
    "thumbnail": "https://drive.google.com/file/d/1zbxwJflt2qQSiUWTzgr1kb08DcU36rRK/view",
    "title": "A dataset and Baselines for Measuring and Predicting the Music Piece Memorability",
    "uid": "56",
    "video": "https://drive.google.com/uc?export=view&id=1sx0VLxNPVR2yhVcF7oafzlE4dwxFYw11"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/11CfMM9NabhgZnbd6yK3IOaivpeEA_5mE/view",
    "abstract": "Optical Music Recognition (OMR) is the field of research that studies how to computationally read music notation from written documents. Thanks to recent advances in computer vision and deep learning, there are successful approaches that can locate the mu",
    "abstract_short": "",
    "author_emails": "carlos.penarrubia@ua.es; carlos.garrido@ua.es; jjvalero@dlsi.ua.es; jcalvo@dlsi.ua.es",
    "authors_and_affil": "Carlos Penarrubia (University of Alicante); Carlos Garrido-Munoz (University of Alicante); Jose J. Valero-Mas (Universitat Pompeu Fabra); Jorge Calvo-Zaragoza (University of Alicante)*",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000020.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000020.pdf",
    "position": "3",
    "poster_pdf": "https://drive.google.com/file/d/1iqZnqyOnUMX_j5Dr0peH4QVEYHhnODbd/view",
    "primary_author": "Jorge Calvo-Zaragoza",
    "primary_email": "jcalvo@dlsi.ua.es",
    "primary_subject": "MIR tasks -> optical music recognition",
    "proceedings_id": "20",
    "secondary_subject": "",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1rQC4xpjRIsFtJh7k8YZpU2c7Ma3AKY1L/view",
    "thumbnail": "https://drive.google.com/file/d/1sxHVg-cit6-6hmsMKt8gi07jQPb01nXH/view",
    "title": "Efficient Notation Assembly in Optical Music Recognition",
    "uid": "38",
    "video": "https://drive.google.com/uc?export=view&id=11CfMM9NabhgZnbd6yK3IOaivpeEA_5mE"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1037kUfS31td5mzFzQ8M_gvlnrQpxUHLH/view",
    "abstract": "Synthesizer parameter inference searches for a set of patch connections and parameters to generate audio that best matches a given target sound. Such optimization tasks benefit from access to accurate gradients. However, typical audio synths incorporate c",
    "abstract_short": "",
    "author_emails": "yutingyang.wh@gmail.com; zejin@adobe.com; af@princeton.edu; connellybarnes@gmail.com",
    "authors_and_affil": "Yuting Yang (Princeton University)*; Zeyu Jin (Adobe Research); Adam Finkelstein (Princeton University); Connelly Barnes (Adobe Research)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000021.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000021.pdf",
    "position": "4",
    "poster_pdf": "https://drive.google.com/file/d/1fao-b0_BcWYeBoCyAM5SPrdromGaVKlV/view",
    "primary_author": "Yuting Yang",
    "primary_email": "yutingyang.wh@gmail.com",
    "primary_subject": "MIR and machine learning for musical acoustics",
    "proceedings_id": "21",
    "secondary_subject": "Applications -> music composition, performance, and production; MIR and machine learning for musical acoustics -> applications of machine learning to musical acoustics; MIR and machine learning for musical acoustics -> applications of musical acoustics to signal synthesis; MIR fundamentals and methodology -> music signal processing",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1VPcJ2KJOWeNnM4Jx3EXbAcimTvOtB9Mz/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1ZR2fsJ7Mh2YO0Q-mu-rHHV6VexG4inz8/view",
    "title": "White Box Search over Audio Synthesizer Parameters",
    "uid": "59",
    "video": "https://drive.google.com/uc?export=view&id=1037kUfS31td5mzFzQ8M_gvlnrQpxUHLH"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1xhJ5KjTYnpdTQB3oFl5CYxaLjUd1DVl3/view",
    "abstract": "Brain decoding allows the read-out of stimulus and mental content from neural activity, and has been utilised in various neural-driven classification tasks related to the music information retrieval community. However, even the relatively simple task of i",
    "abstract_short": "",
    "author_emails": "vkmcheung@gmail.com; lana.okuma@riken.jp; kazuhisa.shibata@riken.jp; k.tsukuda@aist.go.jp; m.goto@aist.go.jp; furuya@csl.sony.co.jp",
    "authors_and_affil": "Vincent K.M. Cheung (Sony Computer Science Laboratories, Inc.)*; Lana Okuma (RIKEN); Kazuhisa Shibata (RIKEN); Kosetsu Tsukuda (National Institute of Advanced Industrial Science and Technology (AIST)); Masataka Goto (National Institute of Advanced Industr",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000022.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000022.pdf",
    "position": "5",
    "poster_pdf": "https://drive.google.com/file/d/1UndCVJ8d5hWou47TfEBwovykn9yq7sQc/view",
    "primary_author": "Vincent K.M. Cheung",
    "primary_email": "vkmcheung@gmail.com",
    "primary_subject": "Human-centered MIR -> user-centered evaluation",
    "proceedings_id": "22",
    "secondary_subject": "Human-centered MIR -> human-computer interaction; Human-centered MIR -> user behavior analysis and mining, user modeling; Knowledge-driven approaches to MIR -> cognitive MIR",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1JPaaTUEg8eS2EbAodC9bQH1iBeKAgWs_/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1YV45v4F9uMKuPcNsJDJ3FiK2c6eJS2et/view",
    "title": "Decoding drums, instrumentals, vocals, and mixed sources in music using human brain activity with fMRI",
    "uid": "63",
    "video": "https://drive.google.com/uc?export=view&id=1xhJ5KjTYnpdTQB3oFl5CYxaLjUd1DVl3"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1mC18LEQOFkb3GyHxXFDdUf5puYgjv_f8/view ",
    "abstract": "Music Emotion Recognition (MER) refers to automatically extracting emotional information from music and predicting its perceived emotions, and it has social and psychological applications. This paper proposes a Dual Attention-based Multi-scale Feature Fus",
    "abstract_short": "",
    "author_emails": "3121358019@stu.xjtu.edu.cn; yxyphd@mail.xjtu.edu.cn; datasonezyc@stu.xjtu.edu.cn; luojingl@stu.xjtu.edu.cn",
    "authors_and_affil": "Liyue Zhang ( Xi\u2019an Jiaotong University)*; Xinyu Yang (Xi'an Jiaotong University); Yichi Zhang (Xi'an Jiaotong University); Jing Luo (Xi'an Jiaotong University)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000023.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000023.pdf",
    "position": "6",
    "poster_pdf": "https://drive.google.com/file/d/1HgMEA6LvG9R0TJFZAuBAFK7uCemTWkJf/view",
    "primary_author": "Liyue Zhang",
    "primary_email": "3121358019@stu.xjtu.edu.cn",
    "primary_subject": "MIR tasks -> automatic classification",
    "proceedings_id": "23",
    "secondary_subject": "MIR fundamentals and methodology -> music signal processing; Musical features and properties -> musical affect, emotion and mood",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1Hka2DKYZV4xEwIxCoCrMnV2NppVZRlOD/edit?usp=sharing&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1xPhQIFxNHwkfqy90YJFTvgrIUIlAQ_wh/view",
    "title": "Dual Attention-based Multi-scale Feature Fusion Approach for Dynamic Music Emotion Recognition",
    "uid": "68",
    "video": "https://drive.google.com/uc?export=view&id=1mC18LEQOFkb3GyHxXFDdUf5puYgjv_f8"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Flog5weyWDCqIryWhj9XDpDo2kmLajwq/view",
    "abstract": "Taking long-term spectral and temporal dependencies into account is essential for automatic piano transcription.\nThis is especially helpful when determining the precise onset and offset for each note in the polyphonic piano content.\nIn this case, we may r",
    "abstract_short": "",
    "author_emails": "keisuke.toyama@sony.com; Taketo.Akama@sony.com; yukara.ikemiya@sony.com; yuta.takida@sony.com; weihsiang.liao@sony.com; Yuhki.Mitsufuji@sony.com",
    "authors_and_affil": "Keisuke Toyama (Sony Group Corporation)*; Taketo Akama (Sony CSL); Yukara Ikemiya (Sony Research); Yuhta Takida (Sony Group Corporation); WeiHsiang Liao (Sony Group Corporation); Yuki Mitsufuji (Sony Group Corporation)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000024.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000024.pdf",
    "position": "7",
    "poster_pdf": "https://drive.google.com/file/d/1VGhS9fshR57vmR2125mYzNEGbYGFmr49/view",
    "primary_author": "Keisuke Toyama",
    "primary_email": "keisuke.toyama@sony.com",
    "primary_subject": "MIR tasks -> music transcription and annotation",
    "proceedings_id": "24",
    "secondary_subject": "",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1SXdfz2nXUf78UXfIWt_1o6KpuJ34XNi9/view",
    "thumbnail": "https://drive.google.com/file/d/1eJKauSWyuJxlw920Kba_NSnEPg6hb_wE/view",
    "title": "Automatic Piano Transcription with Hierarchical Frequency-Time Transformer",
    "uid": "72",
    "video": "https://drive.google.com/uc?export=view&id=1Flog5weyWDCqIryWhj9XDpDo2kmLajwq"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/19PEwJtC-35XcbPaJy5ukN0uBoIzi3d1f/view",
    "abstract": "A descriptive transcription of a violin performance requires detecting not only the notes but also the fine-grained pitch variations, such as vibrato. Most existing deep learning methods for music transcription do not capture these variations and often ne",
    "abstract_short": "",
    "author_emails": "nazifcan.tamer@upf.edu; yigitcan.oezer@audiolabs-erlangen.de; meinard.mueller@audiolabs-erlangen.de; xavier.serra@upf.edu",
    "authors_and_affil": "Nazif Can Tamer (Universitat Pompeu Fabra)*; Yigitcan \u00d6zer (International Audio Laboratories Erlangen); Meinard M\u00fcller (International Audio Laboratories Erlangen); Xavier Serra (Universitat Pompeu Fabra )",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000025.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000025.pdf",
    "position": "8",
    "poster_pdf": "https://drive.google.com/file/d/1KRLWGk5HcUFNG9bYsywrSugL_a8PVh3J/view",
    "primary_author": "Nazif Can Tamer",
    "primary_email": "nazifcan.tamer@upf.edu",
    "primary_subject": "MIR tasks -> music transcription and annotation",
    "proceedings_id": "25",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> music signal processing; MIR tasks -> alignment, synchronization, and score following; Musical features and properties -> expression and performative aspects of music; Musical features and properties -> representations of music",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1lXBcDlLiXWaqWgJsuYfGu0I4QfNjVUeB/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1iBNLcgwzHEbulDBoDNAkAicD-WAITY4N/view",
    "title": "High-Resolution Violin Transcription using Weak Labels",
    "uid": "223",
    "video": "https://drive.google.com/uc?export=view&id=19PEwJtC-35XcbPaJy5ukN0uBoIzi3d1f"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1dGIexp74B_hpMGlqHfo5sfAk-9kHC3vP/view",
    "abstract": "We propose Polyffusion, a diffusion model that generates polyphonic music scores by regarding music as image-like piano roll representations. The model is capable of controllable music generation with two paradigms: internal control and external control. ",
    "abstract_short": "",
    "author_emails": "aik2mlj@gmail.com; at2jjy@gmail.com; gxia@nyu.edu; jzhao@u.nus.edu",
    "authors_and_affil": "Lejun Min (Shanghai Jiao Tong University)*; Junyan Jiang (New York University Shanghai); Gus Xia (New York University Shanghai); Jingwei Zhao (National University of Singapore)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000026.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000026.pdf",
    "position": "9",
    "poster_pdf": "https://drive.google.com/file/d/1LtBs1P-Uf63J208pU7ziT8o5PpmkHfz_/view",
    "primary_author": "Lejun Min",
    "primary_email": "aik2mlj@gmail.com",
    "primary_subject": "MIR tasks -> music generation",
    "proceedings_id": "26",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Knowledge-driven approaches to MIR -> representations of music; MIR fundamentals and methodology -> symbolic music processing",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1iX7xho9P6HIQGKCWBIGty7tfpLav3JXx/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1LpF3DpX_weJWjoczb27TLVUtPHTzrgbL/view",
    "title": "Polyffusion: A Diffusion Model for Polyphonic Score Generation with Internal and External Controls",
    "uid": "51",
    "video": "https://drive.google.com/uc?export=view&id=1dGIexp74B_hpMGlqHfo5sfAk-9kHC3vP"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/12W7e61WVW3bqyfuKWISRz9M2D1UQ_xNb/view",
    "abstract": "This paper introduces a new corpus, CoCoPops: The Coordinated Corpus of Popular Musics. The corpus can be considered a \u201cmeta corpus\u201d in that it both extends and combines two existing corpora\u2014the widely-used McGill Bill-\nboard corpus the and RS200 corpus. ",
    "abstract_short": "",
    "author_emails": "claire.arthur@gatech.edu; natcs@gatech.edu",
    "authors_and_affil": "Claire Arthur (Georgia Institute of Technology)*; Nathaniel Condit-Schultz (Georgia Institute of Technology)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000027.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000027.pdf",
    "position": "10",
    "poster_pdf": "https://drive.google.com/file/d/1Z0vMqYVaW7Hx_nSVl9ZtmYNbiUfJmKd2/view",
    "primary_author": "Claire Arthur",
    "primary_email": "claire.arthur@gatech.edu",
    "primary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "proceedings_id": "27",
    "secondary_subject": "Computational musicology -> digital musicology; Computational musicology -> systematic musicology; Knowledge-driven approaches to MIR -> cognitive MIR; Musical features and properties -> harmony, chords and tonality; Musical features and properties -> melody and motives",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1KkDcqY3RPolBMEjfWE-7URSlQ3S1KqB2/view",
    "thumbnail": "https://drive.google.com/file/d/1BpgecJ0c7FvybDh1WR11NSPBqYqgOoHT/view",
    "title": "The Coordinated Corpus of Popular Musics (CoCoPops): A Meta-Dataset of Melodic and Harmonic Transcriptions",
    "uid": "104",
    "video": "https://drive.google.com/uc?export=view&id=12W7e61WVW3bqyfuKWISRz9M2D1UQ_xNb"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Y2c00qrsceqIemNOanPAnBklWPEowTds/view",
    "abstract": "The research field of music therapy has witnessed a rising interest in recent years to develop and employ computational methods to support therapists in their daily practice. While Music Information Retrieval (MIR) research has identified the area of heal",
    "abstract_short": "",
    "author_emails": "A.Volk@uu.nl; T.Veldhuis@students.uu.nl; katrien.foubert@luca-arts.be; jos.debacker@luca-arts.be",
    "authors_and_affil": "Anja Volk (Utrecht University)*; Tinka Veldhuis (Utrecht University); Katrien Foubert (LUCA School of Arts); Jos De Backer (LUCA School of Arts)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000028.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000028.pdf",
    "position": "11",
    "poster_pdf": "https://drive.google.com/file/d/1PglOD8-VretOEUQOKD9uBkEvbW_NDwOg/view",
    "primary_author": "Anja Volk",
    "primary_email": "A.Volk@uu.nl",
    "primary_subject": "Applications",
    "proceedings_id": "28",
    "secondary_subject": "Applications -> music and health, well-being and therapy",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1jsAeGXPpZqUKDMWd3QFAFPKxPeV8L5OQ/view?usp=share_link",
    "thumbnail": "https://drive.google.com/file/d/1oRXNzZemPVUNgX7VN0k6H4bnZY3aiJet/view?usp=sharing",
    "title": "Towards computational music analysis for music therapy",
    "uid": "153",
    "video": "https://drive.google.com/uc?export=view&id=1Y2c00qrsceqIemNOanPAnBklWPEowTds"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1qU345rZrSCXeeK_k3aylFUWrvOTuQFSW/view",
    "abstract": "Timbre transfer techniques aim at converting the sound of a musical piece generated by one instrument into the same one as if it was played by another instrument, while maintaining as much as possible the content in terms of musical characteristics such a",
    "abstract_short": "",
    "author_emails": "luca.comanducci@polimi.it; fabio.antonacci@polimi.it; augusto.sarti@polimi.it",
    "authors_and_affil": "Luca Comanducci (Politecnico di Milano)*; Fabio Antonacci (Politecnico di Milano); Augusto Sarti (Politecnico di Milano)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000029.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000029.pdf",
    "position": "12",
    "poster_pdf": "https://drive.google.com/file/d/1h2BzyHiG6_5k1XCckQO4CnkWleWcmaCI/view",
    "primary_author": "Luca Comanducci",
    "primary_email": "luca.comanducci@polimi.it",
    "primary_subject": "Musical features and properties -> timbre, instrumentation, and singing voice",
    "proceedings_id": "29",
    "secondary_subject": "MIR tasks -> music synthesis and transformation",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1he6IRIRvPzuDjXgwbvkLmQFxJT1lDH6W/view",
    "thumbnail": "https://drive.google.com/file/d/10Y2cPu2ro6LmAIkvgdXX44MRmrSpSCRP/view",
    "title": "Timbre Transfer using Image-to-Image Denoising Diffusion Implicit Models",
    "uid": "197",
    "video": "https://drive.google.com/uc?export=view&id=1qU345rZrSCXeeK_k3aylFUWrvOTuQFSW"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1IEs2vHDAZxE76QV10AHpIX9h39tol-M_/view",
    "abstract": "Music structure analysis is a core topic in Music Information Retrieval and could be advanced through the inclusion of new data modalities. In this study we consider neural correlates of music structure processing using popular music - specifically chorus",
    "abstract_short": "",
    "author_emails": "neharaj@stanford.edu; blairbo@ccrma.stanford.edu",
    "authors_and_affil": "Neha Rajagopalan (Stanford University)*; Blair Kaneshiro (Stanford University)",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000030.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000030.pdf",
    "position": "13",
    "poster_pdf": "https://drive.google.com/file/d/1UjDa6qx3fJHgfKkmK5PSzSUfz0Q_90B9/view",
    "primary_author": "Neha Rajagopalan",
    "primary_email": "neharaj@stanford.edu",
    "primary_subject": "Knowledge-driven approaches to MIR -> cognitive MIR",
    "proceedings_id": "30",
    "secondary_subject": "Human-centered MIR; MIR fundamentals and methodology -> multimodality; Musical features and properties -> structure, segmentation, and form",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1eOFJuiWD0suR0TYxi9yCC01w-hcK0Isp/view",
    "thumbnail": "https://drive.google.com/file/d/1xn8-GkvSdeBcQZve5kgEwb5eyUfkmO5t/view",
    "title": "Correlation of EEG responses reflects structural similarity of choruses in popular music",
    "uid": "259",
    "video": "https://drive.google.com/uc?export=view&id=1IEs2vHDAZxE76QV10AHpIX9h39tol-M_"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1vrmYxGG7OMYAndo77lzDq7XWkQ3IMGZm/view ",
    "abstract": "\u201cChromatic harmony\u201d is seen as a fundamental part of (extended) tonal music in the Western classical tradition (c.1700\u20131900). It routinely features in core curricula. Yet even in this globalised and data-driven age, 1) there are significant gaps between h",
    "abstract_short": "",
    "author_emails": "mark.r.gotham@durham.ac.uk",
    "authors_and_affil": "Mark R H Gotham (Durham)*",
    "channel_url": "",
    "day": "2",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000031.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000031.pdf",
    "position": "14",
    "poster_pdf": "https://drive.google.com/file/d/16cyvIY6D-V582ZckDmzh1A1ZJZY1UioP/view",
    "primary_author": "Mark R H Gotham",
    "primary_email": "mark.r.gotham@durham.ac.uk",
    "primary_subject": "Knowledge-driven approaches to MIR -> computational music theory and musicology",
    "proceedings_id": "31",
    "secondary_subject": "Computational musicology -> digital musicology; Computational musicology -> mathematical music theory; Computational musicology -> systematic musicology; Musical features and properties -> harmony, chords and tonality; Musical features and properties -> rhythm, beat, tempo",
    "session": "2",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1zAwTQceFmR3DYtAq6JVkF5pmRV25Reuu/view ",
    "thumbnail": "https://drive.google.com/file/d/1zsZG_DIAhhbZa4qyebWH91uv98M7Qmpf/view?usp=sharing",
    "title": "Chromatic Chords in Theory and Practice",
    "uid": "46",
    "video": "https://drive.google.com/uc?export=view&id=1vrmYxGG7OMYAndo77lzDq7XWkQ3IMGZm"
  },
  {
    "AwardNominee": "True",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1yVFoMUKa7i5jE94EA1b_tDCqQ-AhfRT2/view?usp=share_link",
    "abstract": "Intra-opus repeated pattern discovery in polyphonic symbolic music data has  challenges in both algorithm design and data annotation. To solve these challenges, we propose BPS-motif, a new symbolic music dataset containing the note-level annotation of mot",
    "abstract_short": "",
    "author_emails": "willyhsiao@iis.sinica.edu.tw; hong.megan@gmail.com; tearfulcanon@yahoo.com.tw; lisu@iis.sinica.edu.tw",
    "authors_and_affil": "YO-WEI HSIAO (Academia Sinica); TZU-YUN Hung (National Taiwan Normal University); Tsung-Ping Chen (Academia Sinica); Li Su (Academia Sinica)*",
    "channel_url": "",
    "day": "3",
    "long_presentation": "True",
    "paper_presentation": "In Person",
    "pdf_name": "000032.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000032.pdf",
    "position": "0",
    "poster_pdf": "https://drive.google.com/file/d/1CIPZH9MrmtumY-M9GTEaTc9lNeyX2IGq/view",
    "primary_author": "Li Su",
    "primary_email": "lisu@iis.sinica.edu.tw",
    "primary_subject": "MIR fundamentals and methodology -> symbolic music processing",
    "proceedings_id": "32",
    "secondary_subject": "MIR tasks -> pattern matching and detection",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1ylIClYOpST2lAkFnxhxy_bxQ_ZrCE2Sy/view",
    "thumbnail": "https://drive.google.com/file/d/1K2sK-hgZPRH-72jMbxbd1hk23j0FUISY/view?usp=share_link",
    "title": "BPS-Motif: A Dataset for Repeated Pattern Discovery of Polyphonic Symbolic Music",
    "uid": "145",
    "video": "https://drive.google.com/uc?export=view&id=1yVFoMUKa7i5jE94EA1b_tDCqQ-AhfRT2"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1ta1EFfmQaRw6K2M6CwRyOo-YkNPZ-LU0/view",
    "abstract": "Multi-pitch estimation (MPE), the task of detecting active pitches within a polyphonic music recording, has garnered significant research interest in recent years. Most state-of-the-art approaches for MPE are based on deep networks trained using pitch ann",
    "abstract_short": "",
    "author_emails": "michael.krause@audiolabs-erlangen.de; sebastian.strahl@fau.de; meinard.mueller@audiolabs-erlangen.de",
    "authors_and_affil": "Michael Krause (International Audio Laboratories Erlangen)*; Sebastian Strahl (Friedrich-Alexander-Universit\u00e4t Erlangen-N\u00fcrnberg); Meinard M\u00fcller (International Audio Laboratories Erlangen)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000033.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000033.pdf",
    "position": "1",
    "poster_pdf": "https://drive.google.com/file/d/1lGmk9yrSduurAmTnRTTu-POFNk1QwZC2/view",
    "primary_author": "Michael Krause",
    "primary_email": "michael.krause@audiolabs-erlangen.de",
    "primary_subject": "MIR tasks -> music transcription and annotation",
    "proceedings_id": "33",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Knowledge-driven approaches to MIR -> representations of music; MIR tasks -> alignment, synchronization, and score following",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1so1PVXiBTU37EBsnO07FIP0CwmEN5imu/view",
    "thumbnail": "https://drive.google.com/file/d/16Dox9AzY9TJDz8mORKIF7bJ5t57DFtyn/view",
    "title": "Weakly Supervised Multi-Pitch Estimation Using Cross-Version Alignment",
    "uid": "81",
    "video": "https://drive.google.com/uc?export=view&id=1ta1EFfmQaRw6K2M6CwRyOo-YkNPZ-LU0"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1f4QHPE7FMDQO3v3qF2beiqsaujGwSPVw/view",
    "abstract": "We present the Batik plays Mozart Corpus, a piano performance dataset\ncombining professional Mozart piano sonata performances with expert-labelled scores at a note-precise level. The performances originate from a recording by Viennese pianist Roland Batik",
    "abstract_short": "",
    "author_emails": "patricia.hu@jku.at; gerhard.widmer@jku.at",
    "authors_and_affil": "Patricia Hu (Johannes Kepler University)*; Gerhard Widmer (Johannes Kepler University)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000034.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000034.pdf",
    "position": "2",
    "poster_pdf": "https://drive.google.com/file/d/13CtnTbgJlUT0Wz_DtR5x0o4EHEo3DJmk/view",
    "primary_author": "Patricia Hu",
    "primary_email": "patricia.hu@jku.at",
    "primary_subject": "Evaluation, datasets, and reproducibility",
    "proceedings_id": "34",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> annotation protocols; Evaluation, datasets, and reproducibility -> reproducibility; MIR fundamentals and methodology -> symbolic music processing; Musical features and properties -> expression and performative aspects of music",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1DdBgLcfUCRaYq4ZWTXrxfJCyFeX6SXHb/view",
    "thumbnail": "https://drive.google.com/file/d/1ExVUQUbUIa0FRn_fsD_BJrw0C0l6lu8q/view",
    "title": "The Batik-plays-Mozart Corpus:  Linking Performance to Score to Musicological Annotations",
    "uid": "92",
    "video": "https://drive.google.com/uc?export=view&id=1f4QHPE7FMDQO3v3qF2beiqsaujGwSPVw"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1qQz-iD-vnFqK9jd-WOnGhFUbsiWQ_oi5/view",
    "abstract": "Generating a stereophonic presentation from a monophonic audio signal is a challenging open task, especially if the goal is to obtain a realistic spatial imaging with a specific panning of sound elements. In this work, we propose to convert mono to stereo",
    "abstract_short": "",
    "author_emails": "joan.serra@dolby.com; davide.scaini@dolby.com; santiago.pascual@dolby.com; daniel.arteaga@dolby.com; idrojsnop@gmail.com; jeroen.breebaart@dolby.com; giulio.cengarle@dolby.com",
    "authors_and_affil": "Joan Serra (Dolby Laboratories)*; Davide Scaini (Dolby Laboratories); Santiago Pascual (Dolby Laboratories); Daniel Arteaga (Dolby Laboratories); Jordi Pons (Dolby Laboratories); Jeroen Breebaart (Dolby Laboratories); Giulio Cengarle (Dolby Laboratories)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000035.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000035.pdf",
    "position": "3",
    "poster_pdf": "https://drive.google.com/file/d/1jV46u1KFaKVfBtpPoG-FTR1gAckO7j-c/view",
    "primary_author": "Joan Serra",
    "primary_email": "joan.serra@dolby.com",
    "primary_subject": "MIR tasks -> music synthesis and transformation",
    "proceedings_id": "35",
    "secondary_subject": "MIR and machine learning for musical acoustics -> applications of machine learning to musical acoustics; MIR fundamentals and methodology -> music signal processing; MIR tasks -> music generation",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1i7Piz7qfMK495zyorkxV7626LITEohCr/view",
    "thumbnail": "https://drive.google.com/file/d/10yWhpi-LUE35EOagxWXY4NNKLbGsqB4K/view",
    "title": "Mono-to-stereo through parametric stereo generation",
    "uid": "100",
    "video": "https://drive.google.com/uc?export=view&id=1qQz-iD-vnFqK9jd-WOnGhFUbsiWQ_oi5"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Q5im0b7JCRsIYxzLriy1pW-zu_vqpUOt/view",
    "abstract": "Recent developments in MIR have led to several benchmark deep learning models whose embeddings can be used for a variety of downstream tasks. At the same time, the vast majority of these models have been trained on Western pop/rock music and related style",
    "abstract_short": "",
    "author_emails": "cpapaioan@mail.ntua.gr; emmanouil.benetos@qmul.ac.uk; potam@central.ntua.gr",
    "authors_and_affil": "Charilaos Papaioannou (School of ECE, National Technical University of Athens)*; Emmanouil Benetos (Queen Mary University of London); Alexandros Potamianos (National Technical University of Athens)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000036.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000036.pdf",
    "position": "4",
    "poster_pdf": "https://drive.google.com/file/d/1ALR54HMKN2zggi7c8UaT7U0rxIb26i-E/view",
    "primary_author": "Charilaos Papaioannou",
    "primary_email": "cpapaioan@mail.ntua.gr",
    "primary_subject": "Knowledge-driven approaches to MIR -> computational ethnomusicology",
    "proceedings_id": "36",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> music signal processing; MIR tasks -> automatic classification",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1zm48__646MtyzEy_MpQoevBHw3QOXu0Y/view",
    "thumbnail": "https://drive.google.com/file/d/1vs-muvttYYR82INpXW2rz08gmXI4w1eu/view",
    "title": "From West to East: Who can understand the music of the others better?",
    "uid": "101",
    "video": "https://drive.google.com/uc?export=view&id=1Q5im0b7JCRsIYxzLriy1pW-zu_vqpUOt"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1w9jaxLD0ZFatSOtQIh_czdrrtShP9pfH/view",
    "abstract": "Optical Music Recognition (OMR) has become a popular technology to retrieve information present in musical scores in conjunction with the increasing improvement of Deep Learning techniques, which represent the state-of-the-art in the field. However, its e",
    "abstract_short": "",
    "author_emails": "jcmartinez@dlsi.ua.es; adrian.rosello@ua.es; drizo@dlsi.ua.es; jcalvo@dlsi.ua.es",
    "authors_and_affil": "Juan Carlos Martinez-Sevilla (University of Alicante)*; Adri\u00e1n Rosell\u00f3 (Universidad de Alicante); David Rizo (Universidad de Alicante); Jorge Calvo-Zaragoza (University of Alicante)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000037.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000037.pdf",
    "position": "5",
    "poster_pdf": "https://drive.google.com/file/d/1eZPZUrFE9AUGQd_bba8ao7-KkZheW6HE/view",
    "primary_author": "Juan Carlos Martinez-Sevilla",
    "primary_email": "jcmartinez@dlsi.ua.es",
    "primary_subject": "MIR tasks -> optical music recognition",
    "proceedings_id": "37",
    "secondary_subject": "Applications -> music retrieval systems; Evaluation, datasets, and reproducibility -> annotation protocols; Evaluation, datasets, and reproducibility -> evaluation methodology; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1uxBA5g4qOZKuGlxPPZtUPsWY19_GDr3y/view",
    "thumbnail": "https://drive.google.com/file/d/1oXTE-pEwab37bpwkZLtolcKUZCfhrmcc/view",
    "title": "On the Performance of Optical Music Recognition in the Absence of Specific Training Data",
    "uid": "85",
    "video": "https://drive.google.com/uc?export=view&id=1w9jaxLD0ZFatSOtQIh_czdrrtShP9pfH"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1_MuEV4JpOSaYscTf3Vm3f10g07XRwyU7/view",
    "abstract": "We introduce Composer\u2019s Assistant, a system for interactive human-computer composition in the REAPER digital audio workstation. We consider the task of multi-track MIDI infilling when arbitrary track-measures have been deleted from a contiguous slice of m",
    "abstract_short": "",
    "author_emails": "malandro@shsu.edu",
    "authors_and_affil": "Martin E Malandro (Sam Houston State University)*",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000038.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000038.pdf",
    "position": "6",
    "poster_pdf": "https://drive.google.com/file/d/1R7ShCQyyIiT004viq1WSHOZGENpn3MdV/view",
    "primary_author": "Martin E Malandro",
    "primary_email": "malandro@shsu.edu",
    "primary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "proceedings_id": "38",
    "secondary_subject": "Human-centered MIR -> human-computer interaction; MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> music generation",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1dH-663bQnZnxtrM-OwIvkEYbcE6XfoS8/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1PFs40Nj02piatufF5cFyj_rGrnxr51UQ/view",
    "title": "Composer's Assistant: An Interactive Transformer for Multi-Track MIDI Infilling",
    "uid": "113",
    "video": "https://drive.google.com/uc?export=view&id=1_MuEV4JpOSaYscTf3Vm3f10g07XRwyU7"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1nbsc_C380nLwUlgZQJRDJ7Pme8oIapqI/view",
    "abstract": "We introduce a novel audio corpus, the FAV Corpus, of over 400 favorite musical excerpts and pieces, formal analyses, and free-response comments. In a survey, 140 American university students (mostly music majors) were asked to provide three of their favo",
    "abstract_short": "",
    "author_emails": "ethan.s.lustig@gmail.com; dtemperley@esm.rochester.edu",
    "authors_and_affil": "Ethan Lustig (Ethan Lustig)*; David Temperley (Eastman School of Music)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000039.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000039.pdf",
    "position": "7",
    "poster_pdf": "https://drive.google.com/file/d/1bdzme3wv93SkvLyotfnMp72f8tt2jE-s/view",
    "primary_author": "Ethan Lustig",
    "primary_email": "ethan.s.lustig@gmail.com",
    "primary_subject": "Knowledge-driven approaches to MIR -> cognitive MIR",
    "proceedings_id": "39",
    "secondary_subject": "Human-centered MIR -> personalization; Human-centered MIR -> user-centered evaluation; Knowledge-driven approaches to MIR -> representations of music; Musical features and properties -> musical affect, emotion and mood",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1SPxtuSacSrpEatQ66HzdDlZijOIqav2G/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1r5OfnK5jaNHBKre4Wk9uEkbgGr5ZmASG/view",
    "title": "The FAV Corpus: An audio dataset of favorite pieces and excerpts, with formal analyses and music theory descriptors",
    "uid": "114",
    "video": "https://drive.google.com/uc?export=view&id=1nbsc_C380nLwUlgZQJRDJ7Pme8oIapqI"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1h5vskyrQIKUo9cmat3NHqZ1g_a6Uo0-9/view",
    "abstract": "We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic lyrics transcription method achieving state-of-the-art performance on various lyrics transcription datasets, even in challenging genres such as rock and metal. Our novel, training-fre",
    "abstract_short": "",
    "author_emails": "zhuole1025@gmail.com; a43992899@gmail.com; fengshicherish@gmail.com; yinghao.ma@qmul.ac.uk; yizhi.li@sheffield.ac.uk; gezhang@umich.edu; liusi@buaa.edu.cn; rbd@cs.cmu.edu; fujie@baai.ac.cn; c.lin@sheffield.ac.uk; emmanouil.benetos@qmul.ac.uk; wenhuchen@uw",
    "authors_and_affil": "Le Zhuo (Beihang University); Ruibin Yuan (CMU)*; Jiahao Pan (HKBU); Yinghao MA (Queen Mary University of London); Yizhi Li (The University  of Sheffield); Ge Zhang (University of Michigan); Si Liu (Beihang University); Roger B. Dannenberg (School of Comp",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000040.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000040.pdf",
    "position": "8",
    "poster_pdf": "https://drive.google.com/file/d/1rx9VXZ4WlFb24S7awWdrD9cStrRUqLZs/view",
    "primary_author": "Ruibin Yuan",
    "primary_email": "a43992899@gmail.com",
    "primary_subject": "MIR fundamentals and methodology -> lyrics and other textual data",
    "proceedings_id": "40",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> annotation protocols; Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1Wqdk_zo2b95Yt5xxWadc4UP9qRPNSOmB/view",
    "thumbnail": "https://drive.google.com/file/d/1jKPwGZ-emmV1pjh9bqaN0rIq3OrVZeUy/view",
    "title": "LyricWhiz: Robust Multilingual Lyrics Transcription by Whispering to ChatGPT",
    "uid": "117",
    "video": "https://drive.google.com/uc?export=view&id=1h5vskyrQIKUo9cmat3NHqZ1g_a6Uo0-9"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Cx0nL2HWni7ocLN0GUXBM3g-IZ0_oOAi/view?usp=share_link",
    "abstract": "In piano performance, some mistakes stand out to listeners, whereas others may go unnoticed. Former research concluded that the salience of mistakes depended on factors including their contextual appropriateness and a listener\u2019s degree of familiarity to w",
    "abstract_short": "",
    "author_emails": "alia.morsi@upf.edu; tatsumi@lee-lab.org; akira.maezawa@music.yamaha.com; takuya.fujishima@music.yamaha.com; xavier.serra@upf.edu",
    "authors_and_affil": "Alia Morsi (Universitat Pompeu Fabra)*; Kana Tatsumi (Nagoya Institute of Technology); Akira Maezawa (Yamaha Corporation); Takuya Fujishima (Yamaha Corporation); Xavier Serra (Universitat Pompeu Fabra )",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000041.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000041.pdf",
    "position": "9",
    "poster_pdf": "https://drive.google.com/file/d/1FNEeaNq4xjANe8Ui888VjxYaFHT3RO5M/view?usp=sharing",
    "primary_author": "Alia Morsi",
    "primary_email": "alia.morsi@upf.edu",
    "primary_subject": "Applications -> music training and education",
    "proceedings_id": "41",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> annotation protocols; Evaluation, datasets, and reproducibility -> novel datasets and use cases; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR tasks -> automatic classification; Musical features and properties -> expression and performative aspects of music",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1CXo42JTbXW3fRGsSJBkP2cdSRMsykEpY/view",
    "thumbnail": "https://drive.google.com/file/d/15KebKdcDpidnwnwH_OwEdVeHXDBNZOnq/view",
    "title": "SOUNDS OUT OF PL\u00c4CE? SCORE INDEPENDENT DETECTION OF CONSPICUOUS MISTAKE REGIONS IN MIDI PIANO PERFORMANCES",
    "uid": "118",
    "video": "https://drive.google.com/uc?export=view&id=1Cx0nL2HWni7ocLN0GUXBM3g-IZ0_oOAi"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1x7EP-4GCeM9fHEmrMHPozzRj9cldvYty/view",
    "abstract": "We introduce VampNet, a masked acoustic token modeling approach to music synthesis, compression, inpainting, and variation. \nWe use a variable masking schedule during training which allows us to sample coherent music from the model by applying a variety o",
    "abstract_short": "",
    "author_emails": "hugofloresgarcia@u.northwestern.edu; prem@u.northwestern.edu; rithesh@descript.com; pardo@northwestern.edu",
    "authors_and_affil": "Hugo F  Flores Garcia (Northwestern University)*; Prem Seetharaman (Northwestern University); Rithesh Kumar (Descript); Bryan Pardo (Northwestern University)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000042.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000042.pdf",
    "position": "10",
    "poster_pdf": "https://drive.google.com/file/d/1Bt4nhwqEbz0rlNkKwwv_77wA7ThABDDM/view",
    "primary_author": "Hugo F  Flores Garcia",
    "primary_email": "hugofloresgarcia@u.northwestern.edu",
    "primary_subject": "MIR tasks -> music generation",
    "proceedings_id": "42",
    "secondary_subject": "Applications -> music composition, performance, and production; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR tasks -> music synthesis and transformation",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1EsHnwqeJyJ0mZ1k7kSU5XMP644mQNzaZ/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1AYBS6z3-ZfjmS0YXALUbZfOAEj1m9cZ1/view",
    "title": "VampNet: Music Generation via Masked Acoustic Token Modeling",
    "uid": "125",
    "video": "https://drive.google.com/uc?export=view&id=1x7EP-4GCeM9fHEmrMHPozzRj9cldvYty"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1uHn0_0BtDAzHyx2lewrp2xuAMO6BWhWM/view",
    "abstract": "Learning an instrument can be rewarding, but is unavoidably a huge undertaking. Receiving constructive feedback on one\u2019s playing is crucial for improvement. However, personal feedback from an expert instructor is seldom available on demand. The goal motiv",
    "abstract_short": "",
    "author_emails": "yjiang3@richmond.edu",
    "authors_and_affil": "Yucong Jiang (University of Richmond)*",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000043.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000043.pdf",
    "position": "11",
    "poster_pdf": "https://drive.google.com/file/d/117YbHrFSD6J4L5i0bxrzfF02jqLJNkMv/view",
    "primary_author": "Yucong Jiang",
    "primary_email": "yjiang3@richmond.edu",
    "primary_subject": "Applications -> music training and education",
    "proceedings_id": "43",
    "secondary_subject": "Human-centered MIR -> music interfaces and services; MIR fundamentals and methodology -> lyrics and other textual data; MIR fundamentals and methodology -> music signal processing; MIR tasks -> alignment, synchronization, and score following; Musical features and properties -> expression and performative aspects of music",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1J2WyHy2fLUKeJ9Qotj9DPPTMSW0FncDf/view",
    "thumbnail": "https://drive.google.com/file/d/1oPnn8Zl3n7s544Q3m1yvVAsfAfOQGx12/view",
    "title": "Expert and Novice Evaluations of Piano Performances: Criteria for Computer-Aided Feedback",
    "uid": "129",
    "video": "https://drive.google.com/uc?export=view&id=1uHn0_0BtDAzHyx2lewrp2xuAMO6BWhWM"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1glaZPkG4r3hjat4frky06CPI2dJQu7Gv/view",
    "abstract": "Music retrieval and recommendation applications often rely on content features encoded as embeddings, which provide vector representations of items in a music dataset. Numerous complementary embeddings can be derived from processing items originally repre",
    "abstract_short": "",
    "author_emails": "andresferraro@acm.org; jaehun.kim@siriusxm.com; aehmann@pandora.com; soramas@pandora.com; fgouyon@pandora.com",
    "authors_and_affil": "Andres Ferraro (Pandora/SiriusXM)*; Jaehun Kim (Pandora / SiriusXM); Andreas Ehmann (Pandora); Sergio Oramas (Pandora/SiriusXM); Fabien Gouyon (Pandora/SiriusXM)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000044.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000044.pdf",
    "position": "12",
    "poster_pdf": "https://drive.google.com/file/d/1uiop7gVPLVJrYbGF-v71nbYQBKSMEta2/view",
    "primary_author": "Andres Ferraro",
    "primary_email": "andresferraro@acm.org",
    "primary_subject": "Applications -> music retrieval systems",
    "proceedings_id": "44",
    "secondary_subject": "Applications -> music recommendation and playlist generation; MIR fundamentals and methodology -> multimodality; MIR tasks -> similarity metrics; Musical features and properties -> representations of music",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1pqW0gudcaYJBfm-fRgswBUW-GU0yFhyD/view",
    "thumbnail": "https://drive.google.com/file/d/13JN57EZ3ekgQYB9qN-lq9JQSsOIIoRJP/view",
    "title": "Contrastive Learning for Cross-modal Artist Retrieval",
    "uid": "147",
    "video": "https://drive.google.com/uc?export=view&id=1glaZPkG4r3hjat4frky06CPI2dJQu7Gv"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1_NLe1v6sPdZHtLwyG9EPrTKMr4NYPRxr/view",
    "abstract": "The concept of form in music encompasses a wide range of musical aspects, such as phrases and (hierarchical) segmentation, formal functions, cadences and voice-leading schemata, form templates, and repetition structure. In an effort towards a unified mode",
    "abstract_short": "",
    "author_emails": "c.finkensiep@uva.nl; matthieu.haeberle@epfl.ch; friedrich.eisenbrand@epfl.ch; markus.neuwirth@bruckneruni.at; martin.rohrmeier@epfl.ch",
    "authors_and_affil": "Christoph Finkensiep (EPFL)*; Matthieu Haeberle (EPFL); Friedrich Eisenbrand (EPFL); Markus Neuwirth (Anton Bruckner Privatuniversit\u00e4t Linz); Martin A Rohrmeier (Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000045.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000045.pdf",
    "position": "13",
    "poster_pdf": "https://drive.google.com/file/d/1g6z6blYSx82jkFjDSXELbDiatLGdIWnC/view",
    "primary_author": "Christoph Finkensiep",
    "primary_email": "c.finkensiep@uva.nl",
    "primary_subject": "Computational musicology",
    "proceedings_id": "45",
    "secondary_subject": "Computational musicology -> mathematical music theory; Knowledge-driven approaches to MIR -> computational music theory and musicology; MIR fundamentals and methodology -> symbolic music processing; Musical features and properties -> structure, segmentation, and form",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1OIMWWwli7XnTp4FwGPhKI7CRkFU6eu4I/view",
    "thumbnail": "https://drive.google.com/file/d/1Ss8ym3rjM_ntIrTuqqOmIz0uGkcHnFBA/view",
    "title": "Repetition-Structure Inference with Formal Prototypes",
    "uid": "139",
    "video": "https://drive.google.com/uc?export=view&id=1_NLe1v6sPdZHtLwyG9EPrTKMr4NYPRxr"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1z4Ty51ZGrqT_IOXD08dqGK99PE3pHy-a/view",
    "abstract": "Most melodies from the Western common practice period have a harmonic background, i.e., a succession of chords that fit the melody. In this paper we provide a novel approach to infer this harmonic background from the score notation of a melody. We first c",
    "abstract_short": "",
    "author_emails": "peter.van.kranenburg@meertens.knaw.nl; eoin.kearns@meertens.knaw.nl",
    "authors_and_affil": "Peter Van Kranenburg (Utrecht University; Meertens Institute)*; Eoin J Kearns (Meertens Instituut)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000046.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000046.pdf",
    "position": "14",
    "poster_pdf": "https://drive.google.com/file/d/1fti4fr4-IrECum8xM05AGxKQbzfPEd5H/view",
    "primary_author": "Peter Van Kranenburg",
    "primary_email": "peter.van.kranenburg@meertens.knaw.nl",
    "primary_subject": "Musical features and properties -> melody and motives",
    "proceedings_id": "46",
    "secondary_subject": "Computational musicology -> digital musicology; Knowledge-driven approaches to MIR -> computational ethnomusicology; Knowledge-driven approaches to MIR -> computational music theory and musicology; MIR tasks -> music generation; Musical features and properties -> harmony, chords and tonality",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1lHkyLI3JsvIiMtgupLxP5PuRJ4HgwMNB/view",
    "thumbnail": "https://drive.google.com/file/d/1JZegifNNWqpB8I8YSPIMA7B3XB6gssy8/view",
    "title": "Algorithmic Harmonization of Tonal Melodies using Weighted Pitch Context Vectors",
    "uid": "140",
    "video": "https://drive.google.com/uc?export=view&id=1z4Ty51ZGrqT_IOXD08dqGK99PE3pHy-a"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1DWTDGJ_tm3_Bcyy15p7Nd30HtcOWXSd7/view",
    "abstract": "This paper proposes a text-to-lyrics generation method, aiming to provide lyric writing support by suggesting the generated lyrics to users who struggle to find the right words to convey their message. Previous studies on lyrics generation have focused on",
    "abstract_short": "",
    "author_emails": "kento.watanabe@aist.go.jp; m.goto@aist.go.jp",
    "authors_and_affil": "Kento Watanabe (National Institute of Advanced Industrial Science and Technology (AIST))*; Masataka Goto (National Institute of Advanced Industrial Science and Technology (AIST))",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000047.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000047.pdf",
    "position": "15",
    "poster_pdf": "https://drive.google.com/file/d/1Jg01Ghr0AaE6RPHudgG1cW6zqYC9J_hj/view",
    "primary_author": "Kento Watanabe",
    "primary_email": "kento.watanabe@aist.go.jp",
    "primary_subject": "MIR fundamentals and methodology -> lyrics and other textual data",
    "proceedings_id": "47",
    "secondary_subject": "MIR fundamentals and methodology -> multimodality; MIR fundamentals and methodology -> web mining, and natural language processing",
    "session": "3",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1684DsuLAJCz4RzZE8tC_E9dMJ6ID_2Ri/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1le4B70DjdhgRRPBBy7prQnoos-dVUOXB/view",
    "title": "Text-to-lyrics generation with image-based semantics and reduced risk of plagiarism",
    "uid": "142",
    "video": "https://drive.google.com/uc?export=view&id=1DWTDGJ_tm3_Bcyy15p7Nd30HtcOWXSd7"
  },
  {
    "AwardNominee": "True",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1PeK7SflyMaoIyGKdQQ5xnEVKslx39qqp/view?usp=sharing",
    "abstract": "Automatic music captioning, which generates natural language descriptions for given music tracks, holds significant potential for enhancing the understanding and organization of large volumes of musical data. Despite its importance, researchers face chall",
    "abstract_short": "",
    "author_emails": "seungheondoh@kaist.ac.kr; keunwoo@gaudiolab.com; jongpillee@neutune.com; juhan.nam@kaist.ac.kr",
    "authors_and_affil": "Seungheon Doh (KAIST)*; Keunwoo Choi (Gaudio Lab, Inc.); Jongpil Lee (Neutune); Juhan Nam (KAIST)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "True",
    "paper_presentation": "In Person",
    "pdf_name": "000048.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000048.pdf",
    "position": "0",
    "poster_pdf": "https://drive.google.com/file/d/14lE01yNAmpBWGastr-Ve09Cz1YSCiRRH/view?usp=share_link",
    "primary_author": "Seungheon Doh",
    "primary_email": "seungheondoh@kaist.ac.kr",
    "primary_subject": "MIR fundamentals and methodology -> metadata, tags, linked data, and semantic web",
    "proceedings_id": "48",
    "secondary_subject": "MIR fundamentals and methodology -> multimodality; MIR tasks -> automatic classification",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1Po-oyxbz_jj2Q_GI7Z6iaq33io8uWetz/view",
    "thumbnail": "https://drive.google.com/file/d/1COeBiC463MUcyj5fiL2FCvYrt7-DROaX/view?usp=share_link",
    "title": "LP-MusicCaps: LLM-Based Pseudo Music Captioning",
    "uid": "219",
    "video": "https://drive.google.com/uc?export=view&id=1PeK7SflyMaoIyGKdQQ5xnEVKslx39qqp"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1R7OXYDdiBnHw0MOzYYS22E5I0BzAsudD/view",
    "abstract": "Contrastive learning has recently appeared as a well-suited method to find representations of music audio signals that are suitable for structural segmentation. However, most existing unsupervised training strategies omit the notion of repetition and ther",
    "abstract_short": "",
    "author_emails": "morgan.buisson76@gmail.com; brian.mcfee@nyu.edu; slim.essid@telecom-paristech.fr; helene.camille.crayencour@gmail.com",
    "authors_and_affil": "Morgan Buisson (Telecom-Paris)*; Brian McFee (New York University); Slim Essid (Telecom Paris - Institut Polytechnique de Paris); Helene-Camille Crayencour (CNRS)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000049.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000049.pdf",
    "position": "1",
    "poster_pdf": "https://drive.google.com/file/d/1u-UNDElMDqS_kKycvYlk-SzGI-pOCQHW/view",
    "primary_author": "Morgan Buisson",
    "primary_email": "morgan.buisson76@gmail.com",
    "primary_subject": "Musical features and properties -> structure, segmentation, and form",
    "proceedings_id": "49",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Knowledge-driven approaches to MIR -> representations of music; MIR tasks -> pattern matching and detection; Musical features and properties -> representations of music",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1iJMqKCQ62h0s0zs0K_zAWeJF6A9stqMa/view",
    "thumbnail": "https://drive.google.com/file/d/17MzD1-iUXo7XGH97XV0-A-ntlQ2eQ6_j/view",
    "title": "A Repetition-based Triplet Mining Approach for Music Segmentation",
    "uid": "146",
    "video": "https://drive.google.com/uc?export=view&id=1R7OXYDdiBnHw0MOzYYS22E5I0BzAsudD"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1RDdU2rt3vymAbrxAePGUMcqIdsb9alVR/view",
    "abstract": "This paper describes a data-driven framework to parse musical sequences into dependency trees, which are hierarchical structures used in music cognition research and music analysis.\u00a0The parsing involves two steps. First, the input sequence is passed throu",
    "abstract_short": "",
    "author_emails": "francesco.foscarin@jku.at; daniel.harasim@mail.de; gerhard.widmer@jku.at",
    "authors_and_affil": "Francesco Foscarin (Johannes Kepler University Linz)*; Daniel Harasim (\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne); Gerhard Widmer (Johannes Kepler University)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000050.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000050.pdf",
    "position": "2",
    "poster_pdf": "https://drive.google.com/file/d/1nMXueZAbPiQ7mt4ULaRE4rKCIOc2nqb3/view",
    "primary_author": "Francesco Foscarin",
    "primary_email": "francesco.foscarin@jku.at",
    "primary_subject": "MIR fundamentals and methodology -> symbolic music processing",
    "proceedings_id": "50",
    "secondary_subject": "Computational musicology -> digital musicology; Musical features and properties -> harmony, chords and tonality; Musical features and properties -> melody and motives; Musical features and properties -> structure, segmentation, and form",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1MLCi_M9oXIRII9bKkLCNzDqTgaC-4VMx/view",
    "thumbnail": "https://drive.google.com/file/d/1L5mXxa9Uqnaw5ccYK7Yc-lhKO5DKiRa6/view",
    "title": "Predicting Music Hierarchies with a Graph-Based Neural Decoder",
    "uid": "87",
    "video": "https://drive.google.com/uc?export=view&id=1RDdU2rt3vymAbrxAePGUMcqIdsb9alVR"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1-78moijWNgGdVggNJ7Y9-m0Zf-urbrCc/view",
    "abstract": "Soft dynamic time warping (SDTW) is a differentiable loss function that allows for training neural networks from weakly aligned data. Typically, SDTW is used to iteratively compute and refine soft alignments that compensate for temporal deviations between",
    "abstract_short": "",
    "author_emails": "johannes.zeitler@audiolabs-erlangen.de; simon.deniffel@fau.de; michael.krause@audiolabs-erlangen.de; meinard.mueller@audiolabs-erlangen.de",
    "authors_and_affil": "Johannes Zeitler (International Audio Laboratories Erlangen)*; Simon Deniffel (International Audio Laboratories Erlangen); Michael Krause (International Audio Laboratories Erlangen); Meinard M\u00fcller (International Audio Laboratories Erlangen)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000051.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000051.pdf",
    "position": "3",
    "poster_pdf": "https://drive.google.com/file/d/1CJoFlJz2D5RNrZGTpc38z21k2hmv8GNw/view",
    "primary_author": "Johannes Zeitler",
    "primary_email": "johannes.zeitler@audiolabs-erlangen.de",
    "primary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "proceedings_id": "51",
    "secondary_subject": "MIR tasks -> alignment, synchronization, and score following; MIR tasks -> music transcription and annotation",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1KgOMTRro4Y0yzKAU9qPk7tdfTIS7kmQg/view",
    "thumbnail": "https://drive.google.com/file/d/1MLqN1GfLKbUXUNEh7GwFKx8cZ8N1hV3E/view",
    "title": "Stabilizing Training with Soft Dynamic Time Warping: A Case Study for Pitch Class Estimation with Weakly Aligned Targets",
    "uid": "133",
    "video": "https://drive.google.com/uc?export=view&id=1-78moijWNgGdVggNJ7Y9-m0Zf-urbrCc"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/15pD_MIwtse6iGJYq87yB3clpOQF1yXUb/view",
    "abstract": "In this paper, we introduce a computational analysis of the field recording dataset of approximately 700 hours of Korean folk songs, which were recorded around 1980-90s. Because most of the songs were sung by non-expert musicians without accompaniment, th",
    "abstract_short": "",
    "author_emails": "naerin71@sogang.ac.kr; rafael.caro-repetto@kug.ac.at; dasaemj@sogang.ac.kr",
    "authors_and_affil": "Danbinaerin Han (Sogang Univ.); Rafael Caro Repetto (Kunstuniversit\u00e4t Graz); Dasaem Jeong (Sogang University)*",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000052.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000052.pdf",
    "position": "4",
    "poster_pdf": "https://drive.google.com/file/d/17T2UdKBXGrBPEkuGEqXvNkIK7ZzyRdtC/view",
    "primary_author": "Dasaem Jeong",
    "primary_email": "dasaemj@sogang.ac.kr",
    "primary_subject": "Knowledge-driven approaches to MIR -> computational ethnomusicology",
    "proceedings_id": "52",
    "secondary_subject": "Applications -> digital libraries and archives; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Musical features and properties -> melody and motives",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1Tx5Bx2ucf2-M9_Mc8wqFxEss8TtLuo_6/view?usp=share_link",
    "thumbnail": "https://drive.google.com/file/d/1quJ5o6fdJ_S2CUXY8j9UJUsQOMdc2wGb/view",
    "title": "Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song",
    "uid": "149",
    "video": "https://drive.google.com/uc?export=view&id=15pD_MIwtse6iGJYq87yB3clpOQF1yXUb"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1r37TEwXvewpSGLyZrd4H5H5x3qy3zoQG/view",
    "abstract": "\nSignificant strides have been made in creating voice identity representations using speech data. However, the same level of progress has not been achieved for singing voices. To bridge this gap, we suggest a framework for training singer identity encoder",
    "abstract_short": "",
    "author_emails": "bernardo.torres@telecom-paris.fr; stefan.lattner@sony.com; gael.richard@telecom-paris.fr",
    "authors_and_affil": "Bernardo Torres (Telecom Paris, Institut polytechnique de Paris)*; Stefan Lattner (Sony CSL); Ga\u00ebl Richard (Telecom Paris, Institut polytechnique de Paris)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000053.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000053.pdf",
    "position": "5",
    "poster_pdf": "https://drive.google.com/file/d/1B3Wp9yCZoTjOkhRhx831DlTksG2ErIM4/view",
    "primary_author": "Bernardo Torres",
    "primary_email": "bernardo.torres@telecom-paris.fr",
    "primary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "proceedings_id": "53",
    "secondary_subject": "Knowledge-driven approaches to MIR -> representations of music; MIR tasks -> indexing and querying; MIR tasks -> music synthesis and transformation; MIR tasks -> similarity metrics; Musical features and properties -> timbre, instrumentation, and singing voice",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1HFBDu5KoNXU-EOArg0vTfKmpN0XzKmd1/view?usp=share_link",
    "thumbnail": "https://drive.google.com/file/d/1o44VOuMP9sJ60tGerTcJSSM-JyvkUmk2/view",
    "title": "Singer Identity Representation Learning using Self-Supervised Techniques",
    "uid": "204",
    "video": "https://drive.google.com/uc?export=view&id=1r37TEwXvewpSGLyZrd4H5H5x3qy3zoQG"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/10mpCdKtSk5Yoru88f_Xb9G9ws8hWff3Z/view",
    "abstract": "Self-supervised learning (SSL) has shown promising results in various speech and natural language processing applications. However, its efficacy in music information retrieval (MIR) still remains largely unexplored. While previous SSL models pre-trained o",
    "abstract_short": "",
    "author_emails": "yinghao.ma@qmul.ac.uk; a43992899@gmail.com; yizhi.li@sheffield.ac.uk; gezhang@umich.edu; c.lin@sheffield.ac.uk; chenxran@umich.edu; a.ragni@sheffield.ac.uk; hanzhiy@andrew.cmu.edu; emmanouil.benetos@qmul.ac.uk; n.g.gyenge@sheffield.ac.uk; Ruibo.Liu.GR@dar",
    "authors_and_affil": "Yinghao MA (Queen Mary University of London)*; Ruibin Yuan (CMU); Yizhi Li (The University  of Sheffield); Ge Zhang (University of Michigan); Chenghua Lin (University of Sheffield); Xingran Chen (University of Michigan); Anton Ragni (University of Sheffie",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000054.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000054.pdf",
    "position": "6",
    "poster_pdf": "https://drive.google.com/file/d/1_LgOUP9QGXuJMS61lIa-LVW3U_SRovOP/view",
    "primary_author": "Yinghao MA",
    "primary_email": "yinghao.ma@qmul.ac.uk",
    "primary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "proceedings_id": "54",
    "secondary_subject": "Knowledge-driven approaches to MIR -> representations of music; Musical features and properties -> representations of music",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1HH2SDoSjd8NKioAlgVG-nJ5q2Q1TyGDH/view?usp=sharing ",
    "thumbnail": "https://drive.google.com/file/d/1RqHXshWTsX5c4giQIs3sdUJXeG1Rn17I/view",
    "title": "ON THE EFFECTIVENESS OF SPEECH SELF-SUPERVISED LEARNING FOR MUSIC",
    "uid": "154",
    "video": "https://drive.google.com/uc?export=view&id=10mpCdKtSk5Yoru88f_Xb9G9ws8hWff3Z"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Ui91-lbVqm_xEI-oEa0ZmS5DOznR5hdi/view",
    "abstract": "In this paper, we address the beat tracking task which is to predict beat times corresponding to the input audio. Due to the long sequential inputs, it is still challenging to model the global structure efficiently and to deal with the data imbalance betw",
    "abstract_short": "",
    "author_emails": "tian.cheng@aist.go.jp; m.goto@aist.go.jp",
    "authors_and_affil": "Tian Cheng (National Institute of Advanced Industrial Science and Technology (AIST))*; Masataka Goto (National Institute of Advanced Industrial Science and Technology (AIST))",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000055.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000055.pdf",
    "position": "7",
    "poster_pdf": "https://drive.google.com/file/d/1hPkF6xVjUmG1Y_yaqI3bZHbbSRSbS6C2/view",
    "primary_author": "Tian Cheng",
    "primary_email": "tian.cheng@aist.go.jp",
    "primary_subject": "Musical features and properties -> rhythm, beat, tempo",
    "proceedings_id": "55",
    "secondary_subject": "",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1LykqJhYimwUyVR94CJBEZE06_gAwFnOv/view",
    "thumbnail": "https://drive.google.com/file/d/159NbL0joMwLVn2icPdD_E8jgBtBWstvk/view",
    "title": "Transformer-based beat tracking with low-resolution encoder and high-resolution decoder",
    "uid": "150",
    "video": "https://drive.google.com/uc?export=view&id=1Ui91-lbVqm_xEI-oEa0ZmS5DOznR5hdi"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/126Ahz0VboSi0Q92hJ9CKcnW9xLZW0AKQ/view",
    "abstract": "The objective of pattern-matching topics is to gain insights into repetitive patterns within or across various music genres and cultures. This approach aims to shed light on the recurring instances present in diverse musical traditions. The paper presents",
    "abstract_short": "",
    "author_emails": "vanessanina.borsan@univ-lille.fr; mathieu@algomus.fr; richard.groult@univ-rouen.fr; thierry.lecroq@univ-rouen.fr",
    "authors_and_affil": "Vanessa Nina Borsan (Universit\u00e9 de Lille)*; Mathieu Giraud (CNRS, Universit\u00e9 de Lille); Richard Groult (Universit\u00e9 de Rouen Normandie); Thierry Lecroq (Universit\u00e9 de Rouen Normandie )",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000056.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000056.pdf",
    "position": "8",
    "poster_pdf": "https://drive.google.com/file/d/1KnhvnhEOK0CZFBallZ1QasV1vJyWU3-p/view",
    "primary_author": "Vanessa Nina Borsan",
    "primary_email": "vanessanina.borsan@univ-lille.fr",
    "primary_subject": "Knowledge-driven approaches to MIR -> computational ethnomusicology",
    "proceedings_id": "56",
    "secondary_subject": "Computational musicology; Evaluation, datasets, and reproducibility -> novel datasets and use cases; MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> pattern matching and detection; Musical features and properties -> melody and motives",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1bcK02B0QvzxDqayHYDCPRFk9gm0dctro/view",
    "thumbnail": "https://drive.google.com/file/d/1ICMtuG-1wFvmkPbjCbwh0HQLGOoXM-BR/view",
    "title": "Adding Descriptors to Melodies Improves Pattern Matching: A Study on Slovenian Folk Songs",
    "uid": "156",
    "video": "https://drive.google.com/uc?export=view&id=126Ahz0VboSi0Q92hJ9CKcnW9xLZW0AKQ"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1TFaGAyaFQK70F5rd7eXXeu-AlrKcsrzc/view",
    "abstract": "As streaming services have become a main channel for music consumption, they significantly impact various stakeholders: users, artists who provide music, and other professionals working in the music industry. Therefore, it is essential to consider all sta",
    "abstract_short": "",
    "author_emails": "k.dinnissen@uu.nl; christine.bauer@plus.ac.at",
    "authors_and_affil": "Karlijn Dinnissen (Utrecht University)*; Christine Bauer (Paris Lodron University Salzburg)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000057.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000057.pdf",
    "position": "9",
    "poster_pdf": "https://drive.google.com/file/d/1eL3Z3KjS4tNX58UGKSDJBmNCJVt3aRrr/view",
    "primary_author": "Karlijn Dinnissen",
    "primary_email": "k.dinnissen@uu.nl",
    "primary_subject": "Human-centered MIR",
    "proceedings_id": "57",
    "secondary_subject": "Human-centered MIR -> human-computer interaction; Human-centered MIR -> music interfaces and services; Philosophical and ethical discussions -> ethical issues related to designing and implementing MIR tools and technologies",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/12rWDR-MwXe02O4QL4g4Jfx2w-Zee1ue4/view",
    "thumbnail": "https://drive.google.com/file/d/1DU_DRny34LO8VqB7JAsZVh-2XCzbr4h5/view",
    "title": "How Control and Transparency for Users Could Improve Artist Fairness in Music Recommender Systems",
    "uid": "159",
    "video": "https://drive.google.com/uc?export=view&id=1TFaGAyaFQK70F5rd7eXXeu-AlrKcsrzc"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1iJq_hG7isweMKvYvZluLrr9eTSThcwf2/view",
    "abstract": "In light of the enduring success of music streaming services, it is noteworthy that an increasing number of users are positively gravitating toward YouTube as their preferred platform for listening to music. YouTube differs from traditional music streamin",
    "abstract_short": "",
    "author_emails": "chah0623@snu.ac.kr; esshin@snu.ac.kr; gotjs3841@snu.ac.kr; joonlee8@snu.ac.kr; kglee@snu.ac.kr",
    "authors_and_affil": "Ahyeon Choi (Seoul National University)*; Eunsik Shin (Seoul National University); Haesun Joung (Seoul National University); Joongseek Lee (Seoul National University); Kyogu Lee (Seoul National University)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000058.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000058.pdf",
    "position": "10",
    "poster_pdf": "https://drive.google.com/file/d/1oHJYmdzFIa4qVWUCPl3RqvFNDsIZ2UCC/view",
    "primary_author": "Ahyeon Choi",
    "primary_email": "chah0623@snu.ac.kr",
    "primary_subject": "Human-centered MIR -> music interfaces and services",
    "proceedings_id": "58",
    "secondary_subject": "Applications -> music videos, multimodal music systems; Human-centered MIR -> human-computer interaction; Human-centered MIR -> user behavior analysis and mining, user modeling; MIR fundamentals and methodology -> multimodality",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1wwl6z_9B-Gn4dZwKI18n_bgtzZikXjyk/view?usp=sharing",
    "thumbnail": "https://drive.google.com/file/d/1OhjCgBZQFMCRUtI_knEe9dDjBhJwldma/view",
    "title": "Towards a New Interface for Music Listening: A User Experience Study on YouTube",
    "uid": "165",
    "video": "https://drive.google.com/uc?export=view&id=1iJq_hG7isweMKvYvZluLrr9eTSThcwf2"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1YpN38YW55mYs9E4A7jGfwGCr0vyC-Xug/view",
    "abstract": "We present FiloBass: a novel corpus of music scores and annotations which focuses on the important but often overlooked role of the double bass in jazz accompaniment. Inspired by recent works that shed light on the role of the soloist, we offer a collecti",
    "abstract_short": "",
    "author_emails": "j.x.riley@qmul.ac.uk; s.e.dixon@qmul.ac.uk",
    "authors_and_affil": "Xavier Riley (C4DM)*; Simon Dixon (Queen Mary University of London)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000059.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000059.pdf",
    "position": "11",
    "poster_pdf": "https://drive.google.com/file/d/1waVg_oTy_OJxKRZ-2X_9ifOnLd2Kk4m9/view",
    "primary_author": "Xavier Riley",
    "primary_email": "j.x.riley@qmul.ac.uk",
    "primary_subject": "Computational musicology -> digital musicology",
    "proceedings_id": "59",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases; MIR tasks -> music transcription and annotation",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1V_r9FwmTwgE9822y5QIqeiKPx6VIg0vf/view",
    "thumbnail": "https://drive.google.com/file/d/1WCEw7f4sB5C7c6Sd0xIecmNcGYVW2-an/view",
    "title": "FiloBass: A Dataset and Corpus Based Study of Jazz Basslines",
    "uid": "236",
    "video": "https://drive.google.com/uc?export=view&id=1YpN38YW55mYs9E4A7jGfwGCr0vyC-Xug"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1hk8eiCacdB8iR0ZwJu-c5UjEEZ96MJ-w/view",
    "abstract": "In this paper, we propose four different approaches to quantify similarities of compositional texture in symbolically encoded piano music. A melodic contour or harmonic progression can be shaped into a wide variety of different rhythms, densities, or comb",
    "abstract_short": "",
    "author_emails": "louis.couturier@u-picardie.fr; louis.bigo@univ-lille.fr; Florence.Leve@u-picardie.fr",
    "authors_and_affil": "Louis Couturier (MIS, Universit\u00e9 de Picardie Jules Verne)*; Louis Bigo (Universit\u00e9 de Lille); Florence Leve (Universit\u00e9 de Picardie Jules Verne - Lab. MIS - Algomus)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000060.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000060.pdf",
    "position": "12",
    "poster_pdf": "https://drive.google.com/file/d/1Ve5XrBWIIW976IRWGxgCD04HwEDX1MXM/view",
    "primary_author": "Louis Couturier",
    "primary_email": "louis.couturier@u-picardie.fr",
    "primary_subject": "MIR tasks -> similarity metrics",
    "proceedings_id": "60",
    "secondary_subject": "Knowledge-driven approaches to MIR -> computational music theory and musicology; MIR fundamentals and methodology -> symbolic music processing; Musical features and properties",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1e5nisQSGH6XQfI1ZqVnOT4GnuO48W4Tb/view",
    "thumbnail": "https://drive.google.com/file/d/1osooaWw-wYuQdjnUAxqY_R1JsaEi3Av3/view",
    "title": "Comparing Texture in Piano Scores",
    "uid": "170",
    "video": "https://drive.google.com/uc?export=view&id=1hk8eiCacdB8iR0ZwJu-c5UjEEZ96MJ-w"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1h9TxRIy3JM9Xq-zU8aDLzL-SykIampwO/view",
    "abstract": "As corpora of digital musical scores continue to grow, the need for research tools capable of manipulating such data efficiently, with an intuitive interface, and support for a diversity of file formats, becomes increasingly pressing. In response, this pa",
    "abstract_short": "",
    "author_emails": "johannes.hentschel@epfl.ch; andrew.mcleod@idmt.fraunhofer.de; yannis.rammos@epfl.ch; martin.rohrmeier@epfl.ch",
    "authors_and_affil": "Johannes Hentschel (\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne)*; Andrew McLeod (Fraunhofer IDMT); Yannis Rammos (EPFL); Martin A Rohrmeier (Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000061.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000061.pdf",
    "position": "13",
    "poster_pdf": "https://drive.google.com/file/d/18IuVXr59wiqy3Qou-zlpV0bHhNQdSLzo/view",
    "primary_author": "Johannes Hentschel",
    "primary_email": "johannes.hentschel@epfl.ch",
    "primary_subject": "Computational musicology -> digital musicology",
    "proceedings_id": "61",
    "secondary_subject": "Applications -> digital libraries and archives; Evaluation, datasets, and reproducibility -> reproducibility; Knowledge-driven approaches to MIR -> computational music theory and musicology; Knowledge-driven approaches to MIR -> representations of music; MIR tasks -> alignment, synchronization, and score following",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1wJTdo_3MTTpm5mSSvFkkwjpx8DhJY_PM/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1byrcTFqiyyGpMDUoB_vyZYYNYTZNd2-1/view",
    "title": "Introducing Anonymous to leverage the dataframe for processing and analyzing notated music on a very large scale",
    "uid": "52",
    "video": "https://drive.google.com/uc?export=view&id=1h9TxRIy3JM9Xq-zU8aDLzL-SykIampwO"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1H-rOfrOD9_sWFJxM5q8-tM5ybEotVi6_/view",
    "abstract": "We propose multiple methods for effectively training a sequence-to-sequence automatic guitar transcription model which uses tokenized music representation as an output. Our proposed method mainly consists of 1) a hybrid CTC-Attention model for sequence-to",
    "abstract_short": "",
    "author_emails": "kim.sehun@g.sp.m.is.nagoya-u.ac.jp; kazuya.takeda@nagoya-u.jp; tomoki@icts.nagoya-u.ac.jp",
    "authors_and_affil": "Sehun Kim (Nagoya University)*; Kazuya Takeda (Nagoya University); Tomoki Toda (Nagoya University)",
    "channel_url": "",
    "day": "3",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000062.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000062.pdf",
    "position": "14",
    "poster_pdf": "https://drive.google.com/file/d/1nfV8jdToJLq9AjSHgV9299rCC7OtF3YC/view",
    "primary_author": "Sehun Kim",
    "primary_email": "kim.sehun@g.sp.m.is.nagoya-u.ac.jp",
    "primary_subject": "MIR tasks -> music transcription and annotation",
    "proceedings_id": "62",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> music signal processing; MIR fundamentals and methodology -> symbolic music processing",
    "session": "4",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1CDmkdE_W_CPDQc31KxK-bdfIqZ_-pnd7/view",
    "thumbnail": "https://drive.google.com/file/d/1L3Kgc0udyncXQhq8m61wF-U9RYA28pp-/view?usp=share_link",
    "title": "Sequence-to-Sequence Network Training Methods for Automatic Guitar Transcription with Tokenized Outputs",
    "uid": "161",
    "video": "https://drive.google.com/uc?export=view&id=1H-rOfrOD9_sWFJxM5q8-tM5ybEotVi6_"
  },
  {
    "AwardNominee": "True",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1IyGmxASQUh9-Vvokvlyh28TPkuWkhHTL/view",
    "abstract": "In this paper, we address the problem of pitch estimation using self-supervised learning (SSL). The SSL paradigm we use is equivariance to pitch transposition, which enables our model to accurately perform pitch estimation on monophonic audio after being ",
    "abstract_short": "",
    "author_emails": "alain.riou@telecom-paris.fr; stefan.lattner@sony.com; gaetan.hadjeres@sony.com; geoffroy.peeters@telecom-paris.fr",
    "authors_and_affil": "Alain Riou (T\u00e9l\u00e9com Paris, IP Paris, Sony CSL)*; Stefan Lattner (Sony CSL); Ga\u00ebtan Hadjeres (Sony CSL); Geoffroy Peeters (LTCI - T\u00e9l\u00e9com Paris, IP Paris)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "True",
    "paper_presentation": "In Person",
    "pdf_name": "000063.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000063.pdf",
    "position": "0",
    "poster_pdf": "https://drive.google.com/file/d/1E38ECBFAzVt-Z1hvSyPoZb4TIShie6Yy/view",
    "primary_author": "Alain Riou",
    "primary_email": "alain.riou@telecom-paris.fr",
    "primary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "proceedings_id": "63",
    "secondary_subject": "MIR fundamentals and methodology -> music signal processing; MIR tasks -> music transcription and annotation",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/12IZkbSdiISEfU0Gl9tevHd5Va_JLK_Tp/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1-cJpDm-wpwO4_qHAzU5GJlZCDrkxYltb/view",
    "title": "PESTO: Pitch Estimation with Self-supervised Transposition-equivariant Objective",
    "uid": "205",
    "video": "https://drive.google.com/uc?export=view&id=1IyGmxASQUh9-Vvokvlyh28TPkuWkhHTL"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1qalUTMUdUqsIFLg8CNj01uDXllrInwEu/view",
    "abstract": "Throughout history, a consistent temporal and spatial gap has persisted between the inception of novel knowledge and technology and their subsequent adoption for extensive practical utilization. The article explores the dynamic interaction and exchange of",
    "abstract_short": "",
    "author_emails": "vanessanina.borsan@univ-lille.fr; mathieu@algomus.fr; richard.groult@univ-rouen.fr",
    "authors_and_affil": "Vanessa Nina Borsan (Universit\u00e9 de Lille)*; Mathieu Giraud (CNRS, Universit\u00e9 de Lille); Richard Groult (Universit\u00e9 de Rouen Normandie)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000064.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000064.pdf",
    "position": "1",
    "poster_pdf": "https://drive.google.com/file/d/1LeZsFax_jlsd1IS8-wmjaOhkaYhr9KlC/view",
    "primary_author": "Vanessa Nina Borsan",
    "primary_email": "vanessanina.borsan@univ-lille.fr",
    "primary_subject": "Philosophical and ethical discussions",
    "proceedings_id": "64",
    "secondary_subject": "Computational musicology; Human-centered MIR -> human-computer interaction; Human-centered MIR -> user-centered evaluation",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1UD6VHMPMxPyTG18o1bPhFpNE81wkl5EJ/view",
    "thumbnail": "https://drive.google.com/file/d/1QBK2dKq6-Sz-UYq1lNEkOfkXlTQuwCQ4/view",
    "title": "The Games We Play: Exploring The Impact of ISMIR on Musicology",
    "uid": "158",
    "video": "https://drive.google.com/uc?export=view&id=1qalUTMUdUqsIFLg8CNj01uDXllrInwEu"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Yqe3wjveVzIkww9Oo4ljGlszdTPvRqkD/view",
    "abstract": "Supervised music source separation systems using deep learning are trained by minimizing a loss function between pairs of predicted separations and ground-truth isolated sources. However, open datasets comprising isolated sources are few, small, and restr",
    "abstract_short": "",
    "author_emails": "genis.plaja@upf.edu; miron.marius@gmail.com; adithishankar2406@gmail.com; xavier.serra@upf.edu",
    "authors_and_affil": "Gen\u00eds Plaja-Roglans (Music Technology Group)*; Marius Miron (Universitat Pompeu Fabra); Adithi Shankar (Universitat Pompeu Fabra); Xavier Serra (Universitat Pompeu Fabra )",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000065.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000065.pdf",
    "position": "2",
    "poster_pdf": "https://drive.google.com/file/d/1_ANxPnfRtsoefXwSSdezWmwiY54AQx0P/view",
    "primary_author": "Gen\u00eds Plaja-Roglans",
    "primary_email": "genis.plaja@upf.edu",
    "primary_subject": "MIR tasks -> sound source separation",
    "proceedings_id": "65",
    "secondary_subject": "Knowledge-driven approaches to MIR -> computational ethnomusicology; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Musical features and properties -> timbre, instrumentation, and singing voice",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1Er44BwZDEQolLDoWF_KXJw3nIw4g9mPf/view",
    "thumbnail": "https://drive.google.com/file/d/1g2JQFuTdYhuXCy3WOs9CG90ko3Yt4cj-/view",
    "title": "Carnatic Singing Voice Separation Using Cold Diffusion on Training Data with Bleeding",
    "uid": "176",
    "video": "https://drive.google.com/uc?export=view&id=1Yqe3wjveVzIkww9Oo4ljGlszdTPvRqkD"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1k3TdguuXpFUM-8BYGn6q_stKRRaIbvua/view",
    "abstract": "When a user listens to a song for the first time, what musical factors (e.g., melody, tempo, and lyrics) influence the user's decision to like or dislike the song? An answer to this question would enable researchers to more deeply understand how people in",
    "abstract_short": "",
    "author_emails": "k.tsukuda@aist.go.jp; t.nakano@aist.go.jp; masahiro.hamasaki@aist.go.jp; m.goto@aist.go.jp",
    "authors_and_affil": "Kosetsu Tsukuda (National Institute of Advanced Industrial Science and Technology (AIST))*; Tomoyasu Nakano (National Institute of Advanced Industrial Science and Technology (AIST)); Masahiro Hamasaki (National Institute of Advanced Industrial Science and",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000066.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000066.pdf",
    "position": "3",
    "poster_pdf": "https://drive.google.com/file/d/1B9kmqixemKtVnFleUFKGTboodh8t2FFr/view",
    "primary_author": "Kosetsu Tsukuda",
    "primary_email": "k.tsukuda@aist.go.jp",
    "primary_subject": "Human-centered MIR",
    "proceedings_id": "66",
    "secondary_subject": "",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1dqR2PW5Tqb5BDpQxWAM9hugq7u6CHq53/view",
    "thumbnail": "https://drive.google.com/file/d/1NvvZYM7IVTorRFkOerJ_SMLAmO7tfeEC/view",
    "title": "Unveiling the Impact of Musical Factors in Judging a Song on First Listen: Insights from a User Survey",
    "uid": "179",
    "video": "https://drive.google.com/uc?export=view&id=1k3TdguuXpFUM-8BYGn6q_stKRRaIbvua"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1A3OyouqQ6G7G0bXYC5zUaX0-67Kc6WNn/view",
    "abstract": "The historical development of medieval plainchant melodies is an intriguing musicological topic that invites computational approaches to study it at scale. Plainchant melodies can be represented as strings from a limited alphabet, hence making it technica",
    "abstract_short": "",
    "author_emails": "hajicj@ufal.mff.cuni.cz; gaballench@qmul.ac.uk; muhlova@mail.cuni.cz; vlhova@mua.cas.cz",
    "authors_and_affil": "Jan Haji_, jr. (Charles University)*; Gustavo Ballen (dos Reis research group, School of Biological and Behavioural Sciences, Queen Mary University of London); Kl\u00e1ra M\u00fchlov\u00e1 (Institute of Musicology, Faculty of Arts, Masaryk University); Hana Vlhov\u00e1-W\u00f6rne",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000067.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000067.pdf",
    "position": "4",
    "poster_pdf": "https://drive.google.com/file/d/1njr07WsSeq2iWcgYfvi2NwhY5aE-RDkt/view",
    "primary_author": "Jan Haji\u010d, jr.",
    "primary_email": "hajicj@ufal.mff.cuni.cz",
    "primary_subject": "Computational musicology -> digital musicology",
    "proceedings_id": "67",
    "secondary_subject": "Applications -> digital libraries and archives; Knowledge-driven approaches to MIR -> computational ethnomusicology; Knowledge-driven approaches to MIR -> computational music theory and musicology",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1lg_PIDjHx8xSWPmiJOV-K7pIuMi8mXH6/view",
    "thumbnail": "https://drive.google.com/file/d/1xmnYaY-xg1BuYEeW22XyKuO_h7mx1IwF/view",
    "title": "Towards Building a Phylogeny of Gregorian Chant Melodies",
    "uid": "180",
    "video": "https://drive.google.com/uc?export=view&id=1A3OyouqQ6G7G0bXYC5zUaX0-67Kc6WNn"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1hh6L-FIc_3Ptt_MrZHeFD8-uQw88a4tm/view",
    "abstract": "Music classification has been one of the most popular tasks in the field of music information retrieval. With the development of deep learning models, the last decade has seen impressive improvements in a wide range of classification tasks. However, the i",
    "abstract_short": "",
    "author_emails": "yding402@gatech.edu; alexander.lerch@gatech.edu",
    "authors_and_affil": "Yiwei Ding (Georgia Institute of Technology)*; Alexander Lerch (Georgia Institute of Technology)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000068.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000068.pdf",
    "position": "5",
    "poster_pdf": "https://drive.google.com/file/d/1jDmXNpEtDnYx13zWdgBWZxFv07--79Xw/view",
    "primary_author": "Yiwei Ding",
    "primary_email": "yding402@gatech.edu",
    "primary_subject": "Knowledge-driven approaches to MIR",
    "proceedings_id": "68",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Knowledge-driven approaches to MIR -> representations of music; MIR tasks -> automatic classification; Musical features and properties -> representations of music",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1gbLLZ2Do2-u0GRmlG5HMxUDseG0rPOjV/view",
    "thumbnail": "https://drive.google.com/file/d/1yHE7wVW21ORQmtobdGp71QvM9lfIrxS6/view",
    "title": "Audio Embeddings as Teachers for Music Classification",
    "uid": "182",
    "video": "https://drive.google.com/uc?export=view&id=1hh6L-FIc_3Ptt_MrZHeFD8-uQw88a4tm"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1vbIybJB4N66A0xQ7yAWzKkquZYAmJtTm/view",
    "abstract": "We present ScorePerformer, an encoder-decoder transformer with hierarchical style encoding heads for controllable rendering of expressive piano music performances. We design a tokenized representation of symbolic score and performance music, the Score Per",
    "abstract_short": "",
    "author_emails": "Ilya.Borovik@skoltech.ru; cmt3@viro.name",
    "authors_and_affil": "Ilya Borovik (Skolkovo Institute of Science and Technology)*; Vladimir Viro (Peachnote)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000069.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000069.pdf",
    "position": "6",
    "poster_pdf": "https://drive.google.com/file/d/13j1Zkl2_WFOTKRA-WgzOy_2G3UII5ipa/view",
    "primary_author": "Ilya Borovik",
    "primary_email": "Ilya.Borovik@skoltech.ru",
    "primary_subject": "Musical features and properties -> expression and performative aspects of music",
    "proceedings_id": "69",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> alignment, synchronization, and score following; Musical features and properties -> representations of music",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1UPfJULh0vG7aKP5C6LjqFMay-KYTbXdx/view",
    "thumbnail": "https://drive.google.com/file/d/1nk1g0AAilKaTQaBbUu3WUkZFyruTUNRl/view",
    "title": "ScorePerformer: Expressive Piano Performance Rendering with Fine-Grained Control",
    "uid": "183",
    "video": "https://drive.google.com/uc?export=view&id=1vbIybJB4N66A0xQ7yAWzKkquZYAmJtTm"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/11FgFY287Aemntt0pXL5tCnLJ-WtRRXVA/view",
    "abstract": "Roman Numeral analysis is the important task of identifying chords and their functional context in pieces of tonal music. \nThis paper presents a new approach to automatic Roman Numeral analysis in symbolic music. While existing techniques rely on an inter",
    "abstract_short": "",
    "author_emails": "emmanouil.karystinaios@jku.at; gerhard.widmer@jku.at",
    "authors_and_affil": "Emmanouil Karystinaios (Johannes Kepler University)*; Gerhard Widmer (Johannes Kepler University)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000070.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000070.pdf",
    "position": "7",
    "poster_pdf": "https://drive.google.com/file/d/16X_gLqPUC64Oi48kfzaSCe0MErT9aY5h/view",
    "primary_author": "Emmanouil Karystinaios",
    "primary_email": "emmanouil.karystinaios@jku.at",
    "primary_subject": "Musical features and properties -> harmony, chords and tonality",
    "proceedings_id": "70",
    "secondary_subject": "Knowledge-driven approaches to MIR -> computational music theory and musicology; MIR fundamentals and methodology -> symbolic music processing",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1_54nqe69FU_v39lSQMy8Et1-w_tm_KCy/view",
    "thumbnail": "https://drive.google.com/file/d/13jGWJNT1KC01cosmgMgCJ9haPcGJOVUz/view",
    "title": "Roman Numeral Analysis with Graph Neural Networks: Onset-wise Predictions from Note-wise Features",
    "uid": "89",
    "video": "https://drive.google.com/uc?export=view&id=11FgFY287Aemntt0pXL5tCnLJ-WtRRXVA"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/16_7tMqQrmgDBP_AGtaBTo9DEsTD1XgV0/view",
    "abstract": "We present a system to assist Subject Matter Experts (SMEs) to curate large online music catalogs. The system detects releases that are incorrectly attributed to an artist discography (misattribution), when the discography of a single artist is incorrectl",
    "abstract_short": "",
    "author_emails": "brianr@spotify.com; desih@spotify.com; marianob@spotify.com",
    "authors_and_affil": "Brian Regan (Spotify)*; Desislava Hristova (Spotify); Mariano Beguerisse-D\u00edaz (Spotify)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000071.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000071.pdf",
    "position": "8",
    "poster_pdf": "https://drive.google.com/file/d/11bJaG1XGVRnokhKwaR47howB-BdQakK_/view",
    "primary_author": "Brian Regan",
    "primary_email": "brianr@spotify.com",
    "primary_subject": "Applications -> digital libraries and archives",
    "proceedings_id": "71",
    "secondary_subject": "Human-centered MIR -> user-centered evaluation; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> metadata, tags, linked data, and semantic web; MIR fundamentals and methodology -> multimodality",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/10tnkLU92yPqP-HA8sU9480-C3toBPPxM/view",
    "thumbnail": "https://drive.google.com/file/d/1yTPpHfuqjLvRoKFjVoXHZlfHWnzqp_SN/view",
    "title": "Semi-Automated Music Catalog Curation Using Audio and Metadata",
    "uid": "199",
    "video": "https://drive.google.com/uc?export=view&id=16_7tMqQrmgDBP_AGtaBTo9DEsTD1XgV0"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/19KmwqtzdT_U7Hmx7Is-_WjRsm7qDP7Qv/view",
    "abstract": "Musical instrument recognition enables applications such as instrument-based music search and audio manipulation, which are highly sought-after processes in everyday music consumption and production. Despite continuous progresses, advances in automatic mu",
    "abstract_short": "",
    "author_emails": "i.p.samiotis@tudelft.nl; a.bozzon@tudelft.nl; c.lofi@tudelft.nl",
    "authors_and_affil": "Ioannis Petros Samiotis (Delft University of Technology)*; Alessandro  Bozzon (Delft University of Technology); Christoph Lofi (TU Delft)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000072.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000072.pdf",
    "position": "9",
    "poster_pdf": "https://drive.google.com/file/d/1FzPdsSh7yjCQQ6JPZHd0ZSlK_ue6tfjb/view",
    "primary_author": "Ioannis Petros Samiotis",
    "primary_email": "i.p.samiotis@tudelft.nl",
    "primary_subject": "Human-centered MIR",
    "proceedings_id": "72",
    "secondary_subject": "Human-centered MIR -> human-computer interaction; Human-centered MIR -> music interfaces and services; MIR tasks -> music transcription and annotation; MIR tasks -> sound source separation; Musical features and properties -> timbre, instrumentation, and singing voice",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1UnOhoLaOwkjl8pG7-UemEH2zcSXSkFKH/view",
    "thumbnail": "https://drive.google.com/file/d/1LwNRWoWsIIYeECYsJx7cE_v1yoswxU8h/view",
    "title": "Crowd's Performance on Temporal  Activity Detection of Musical Instruments in Polyphonic Music",
    "uid": "202",
    "video": "https://drive.google.com/uc?export=view&id=19KmwqtzdT_U7Hmx7Is-_WjRsm7qDP7Qv"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1tpXSRd_xGFPNBldII75K1wZsAsoQ068d/view",
    "abstract": "In this paper, we introduce the MoisesDB dataset for musical source separation. It consists of 240 tracks from 45 artists, covering twelve musical genres. \nFor each song, we provide its individual audio sources, organized in a two-level hierarchical taxon",
    "abstract_short": "",
    "author_emails": "igor@moises.ai; felipe.araujo@moises.ai; filip.korzeniowski@moises.ai; richard.vogl@moises.ai",
    "authors_and_affil": "Igor G. Pereira (Moises.AI)*; Felipe Araujo (Moises.AI); Filip Korzeniowski (Moises.AI); Richard Vogl (moises.ai)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000073.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000073.pdf",
    "position": "10",
    "poster_pdf": "https://drive.google.com/file/d/1x1nTGSfK6jUcphVYGlgKgXXVZAmsKItX/view",
    "primary_author": "Igor G. Pereira",
    "primary_email": "igor@moises.ai",
    "primary_subject": "Evaluation, datasets, and reproducibility",
    "proceedings_id": "73",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases; MIR tasks -> sound source separation",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1sTOnnJJLI9pUjLeCpKS6e5IFqxFu5MDp/view",
    "thumbnail": "https://drive.google.com/file/d/1V1bBCq2K2HBY0ULXBjuFENZg4q30Y7oy/view",
    "title": "MoisesDB: A Dataset For Source Separation Beyond 4 Stems",
    "uid": "160",
    "video": "https://drive.google.com/uc?export=view&id=1tpXSRd_xGFPNBldII75K1wZsAsoQ068d"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/19qDR-nUFtQUAxJE0km1U2Kzvm-HQvO7o/view",
    "abstract": "Modeling the temporal unfolding of musical events and its interpretation in terms of hierarchical relations is a common theme in music theory, cognition, and composition. To faithfully encode such relations, we need an elegant way to represent both the se",
    "abstract_short": "",
    "author_emails": "zeng.ren@epfl.ch; wulfram.gerstner@epfl.ch; martin.rohrmeier@epfl.ch",
    "authors_and_affil": "Zeng Ren (EPFL)*; Wulfram Gerstner (EPFL); Martin A Rohrmeier (Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000074.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000074.pdf",
    "position": "11",
    "poster_pdf": "https://drive.google.com/file/d/1MnOQegGQp3oL4vayaPQrNvkGMMfmjf7e/view",
    "primary_author": "Zeng Ren",
    "primary_email": "zeng.ren@epfl.ch",
    "primary_subject": "Knowledge-driven approaches to MIR -> representations of music",
    "proceedings_id": "74",
    "secondary_subject": "Computational musicology; Knowledge-driven approaches to MIR -> computational music theory and musicology; Musical features and properties -> harmony, chords and tonality; Musical features and properties -> structure, segmentation, and form",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1PSWl8tbBiqMPqK08h120HQTJ-6Po7_FL/view",
    "thumbnail": "https://drive.google.com/file/d/1eO7LLD33O0ycx-w_RRKBtASn3kshtHz0/view",
    "title": "Music as flow: a formal representation of hierarchical processes in music",
    "uid": "206",
    "video": "https://drive.google.com/uc?export=view&id=19qDR-nUFtQUAxJE0km1U2Kzvm-HQvO7o"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1ZV51EZdGgtBusGXIBV4fGjiTy9lexm-I/view",
    "abstract": "Symbolic Music Alignment is the process of matching\nperformed MIDI notes to corresponding score notes. In\nthis paper, we introduce a reinforcement learning (RL)-\nbased online symbolic music alignment technique. The\nRL agent \u2014 an attention-based neural net",
    "abstract_short": "",
    "author_emails": "silvan.peter@jku.at",
    "authors_and_affil": "Silvan Peter (JKU)*",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000075.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000075.pdf",
    "position": "12",
    "poster_pdf": "https://drive.google.com/file/d/1g3T20qaG1EU4Py-guad-sUdCr4Tkd14s/view",
    "primary_author": "Silvan Peter",
    "primary_email": "silvan.peter@jku.at",
    "primary_subject": "MIR tasks -> alignment, synchronization, and score following",
    "proceedings_id": "75",
    "secondary_subject": "MIR fundamentals and methodology -> symbolic music processing",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1OrnnHfjrazGOuey-mIpeXrapOu9mmrZ_/view",
    "thumbnail": "https://drive.google.com/file/d/1_obDs8CHpqCJJyW1j0WiJ7wNNciCcT_5/view",
    "title": "Online Symbolic Music Alignment with Offline Reinforcement Learning",
    "uid": "208",
    "video": "https://drive.google.com/uc?export=view&id=1ZV51EZdGgtBusGXIBV4fGjiTy9lexm-I"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "",
    "abstract": "Synthesizers are widely used electronic musical instruments. Given an input sound, inferring the underlying synthesizer's parameters to reproduce it is a difficult task known as sound-matching. In this work, we tackle the problem of automatic sound matchi",
    "abstract_short": "",
    "author_emails": "barkanoren1@gmail.com; sshlomi6@gmail.com; noyuzrad@mail.tau.ac.il; moshe13269@gmail.com; alicranck@gmail.com; noamk@tauex.tau.ac.il",
    "authors_and_affil": "Oren Barkan (Microsoft); Shlomi Shvartzamn (Tel Aviv University ); Noy Uzrad  (Tel Aviv University ); Moshe Laufer  (Tel Aviv University); Almog Elharar (Tel Aviv University); Noam Koenigstein (Tel Aviv University)*",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000076.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000076.pdf",
    "position": "13",
    "poster_pdf": "",
    "primary_author": "Noam Koenigstein",
    "primary_email": "noamk@tauex.tau.ac.il",
    "primary_subject": "MIR tasks -> music synthesis and transformation",
    "proceedings_id": "76",
    "secondary_subject": "MIR tasks -> music generation",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "",
    "thumbnail": "",
    "title": "INVERSYNTH II: SOUND MATCHING VIA SELF-SUPERVISED SYNTHESIZER-PROXY AND INFERENCE-TIME FINETUNING",
    "uid": "209",
    "video": ""
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/10IuEp3DDBqV0F0WM4u3nodR54J9fjajt/view",
    "abstract": "Query-by-Humming (QbH) is a task that involves finding the most relevant song based on a hummed or sung fragment. Despite recent successful commercial solutions, implementing QbH systems remains challenging due to the lack of high-quality datasets for tra",
    "abstract_short": "",
    "author_emails": "amatoamant@gmail.com; lamanov.dmitry@huawei.com; maksim.titov@huawei.com; ivan.vovk@huawei.com; iamakarov@misis.ru; kudinov.mikhail@huawei.com",
    "authors_and_affil": "Amantur Amatov (Higher School of Economics)*; Dmitry Lamanov (Huawei Noah's Ark Lab); Maksim Titov (Huawei Noah's Ark Lab); Ivan Vovk (Huawei Noah's Ark Lab); Ilya Makarov (AI Center, NUST MISiS); Mikhail Kudinov (Huawei Noah's Ark Lab)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000077.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000077.pdf",
    "position": "14",
    "poster_pdf": "https://drive.google.com/file/d/10HbIvg_hiwfZmJB1HVd-v8MI-yOLmF-2/view",
    "primary_author": "Amantur Amatov",
    "primary_email": "amatoamant@gmail.com",
    "primary_subject": "Applications -> music retrieval systems",
    "proceedings_id": "77",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases; MIR tasks -> fingerprinting; MIR tasks -> indexing and querying",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1uSA4UuV6xLGU70470OraRCOE2sP38IWf/view",
    "thumbnail": "https://drive.google.com/file/d/1PEvsaujw2Rjs6gVj3n09ox3I_Puiszh2/view",
    "title": "A Semi-Supervised Deep Learning Approach to Dataset Collection for Query-by-Humming Task",
    "uid": "210",
    "video": "https://drive.google.com/uc?export=view&id=10IuEp3DDBqV0F0WM4u3nodR54J9fjajt"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1rPO9dd5FjAqQ76wSk7iYdjBQC7srhTMm/view",
    "abstract": "In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First",
    "abstract_short": "",
    "author_emails": "k5shao@ucsd.edu; knutchen@ucsd.edu; tberg@ucsd.edu; sdubnov@ucsd.edu",
    "authors_and_affil": "Keren Shao (UCSD)*; Ke Chen (University of California San Diego); Taylor Berg-Kirkpatrick (UCSD); Shlomo Dubnov (UC San Diego)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000078.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000078.pdf",
    "position": "15",
    "poster_pdf": "https://drive.google.com/file/d/15HMp76uOrrL_9hjVj0PTJpPPbNL6r8QI/view",
    "primary_author": "Keren Shao",
    "primary_email": "k5shao@ucsd.edu",
    "primary_subject": "Musical features and properties -> melody and motives",
    "proceedings_id": "78",
    "secondary_subject": "MIR fundamentals and methodology -> music signal processing; MIR tasks -> automatic classification",
    "session": "5",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1ZS0w-QK8R-VtmSFhWl1cnbQ_rWmYmazP/view",
    "thumbnail": "https://drive.google.com/file/d/1V9iJvFXFF38FppM-7nhlYT1e_CSYX8mF/view",
    "title": "Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction",
    "uid": "212",
    "video": "https://drive.google.com/uc?export=view&id=1rPO9dd5FjAqQ76wSk7iYdjBQC7srhTMm"
  },
  {
    "AwardNominee": "True",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1i46u1z9bGukUxzCAxTxrIgyix-uKQ0X4/view",
    "abstract": "This paper introduces GlOttal-flow LPC Filter (GOLF), a novel method for singing voice synthesis (SVS) that exploits the physical characteristics of the human voice using differentiable digital signal processing. GOLF employs a glottal model as the harmon",
    "abstract_short": "",
    "author_emails": "chin-yun.yu@qmul.ac.uk; george.fazekas@qmul.ac.uk",
    "authors_and_affil": "Chin-Yun Yu (Queen Mary University of London)*; George Fazekas (QMUL)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "True",
    "paper_presentation": "In Person",
    "pdf_name": "000079.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000079.pdf",
    "position": "0",
    "poster_pdf": "https://drive.google.com/file/d/1gZIPuuU2QzKivJaIGpM2Uh2mgBND_ia6/view",
    "primary_author": "Chin-Yun Yu",
    "primary_email": "chin-yun.yu@qmul.ac.uk",
    "primary_subject": "MIR tasks -> music synthesis and transformation",
    "proceedings_id": "79",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> music signal processing; Musical features and properties -> timbre, instrumentation, and singing voice",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1VNQc3u1tr_5yfqQBiEZ-IX73UfOuqWiv/view",
    "thumbnail": "https://drive.google.com/file/d/1esbWBjCD4bL-1b1R334yin24FFIZZVwo/view",
    "title": "SINGING VOICE SYNTHESIS USING DIFFERENTIABLE LPC AND GLOTTAL-FLOW-INSPIRED WAVETABLES",
    "uid": "220",
    "video": "https://drive.google.com/uc?export=view&id=1i46u1z9bGukUxzCAxTxrIgyix-uKQ0X4"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1nmlSKLZSPGNvc7LmNLfNGa5RkDpdZI1G/view",
    "abstract": "Automatic harmonic analysis of symbolic music is an important\nand useful task for both composers and listeners.\nThe task consists of two components: recognizing harmony\nlabels and finding their time boundaries. Most of the\nprevious attempts focused on the",
    "abstract_short": "",
    "author_emails": "qyang15@ur.rochester.edu; fcwitkow@ur.rochester.edu; zhiyao.duan@rochester.edu",
    "authors_and_affil": "Qiaoyu Yang (University of Rochester)*; Frank Cwitkowitz (University of Rochester); Zhiyao Duan (Unversity of Rochester)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000080.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000080.pdf",
    "position": "1",
    "poster_pdf": "https://drive.google.com/file/d/1o-KmlLu-lsRgMxrSIRF-Hf-zaY8299hY/view?usp=sharing",
    "primary_author": "Qiaoyu Yang",
    "primary_email": "qyang15@ur.rochester.edu",
    "primary_subject": "Musical features and properties",
    "proceedings_id": "80",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Musical features and properties -> harmony, chords and tonality",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1-aMmN-KI1fD0HaifkFwIDZqiaDZmzpDV/view",
    "thumbnail": "https://drive.google.com/file/d/1w-loLMW-_BmPFrdJcciLHoltDTHCKPVS/view",
    "title": "Harmonic Analysis with Neural Semi-CRF",
    "uid": "264",
    "video": "https://drive.google.com/uc?export=view&id=1nmlSKLZSPGNvc7LmNLfNGa5RkDpdZI1G"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1wd_U2mEHtz_d_6P8HsDPcxC-voNPH4TJ/view",
    "abstract": "Music Performance Analysis is based on the evaluation of performance parameters such as pitch, dynamics, timbre, tempo and timing. While timbre is the least specific parameter among these and is often only implicitly understood, prominent brass pedagogues",
    "abstract_short": "",
    "author_emails": "ninad.puranik@mail.mcgill.ca; alberto.acquilino@mail.mcgill.ca; ichiro.fujinaga@mcgill.ca; gary.scavone@mcgill.ca",
    "authors_and_affil": "Ninad Puranik (McGill University ); Alberto Acquilino (McGill University)*; Ichiro Fujinaga (McGill University); Gary Scavone (McGill University)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000081.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000081.pdf",
    "position": "2",
    "poster_pdf": "https://drive.google.com/file/d/1yO2gg3CZlQDiddv2qQVZQLPXz2S9bDSm/view",
    "primary_author": "Alberto Acquilino",
    "primary_email": "alberto.acquilino@mail.mcgill.ca",
    "primary_subject": "Musical features and properties -> timbre, instrumentation, and singing voice",
    "proceedings_id": "81",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR and machine learning for musical acoustics -> applications of machine learning to musical acoustics; MIR fundamentals and methodology -> music signal processing; MIR tasks -> automatic classification",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1u0LgGMqp0_BNni8LK3A3MpyenzDkci2j/view",
    "thumbnail": "https://drive.google.com/file/d/178jwgniWfuX8pqTIDgNAKf1zs3NnbG48/view",
    "title": "A Dataset and Baseline for Automated Assessment of Timbre Quality in Trumpet Sound",
    "uid": "213",
    "video": "https://drive.google.com/uc?export=view&id=1wd_U2mEHtz_d_6P8HsDPcxC-voNPH4TJ"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1QqrLFOACnxQebUM1qdQT2AmCTegxTCmz/view",
    "abstract": "We propose different methods for alternative representation and visual augmentation of sheet music that help users gain an overview of general structure, repeating patterns, and the similarity of segments. To this end, we explored mapping the overall simi",
    "abstract_short": "",
    "author_emails": "frank.heyen@visus.uni-stuttgart.de; quynh.ngo@visus.uni-stuttgart.de; Michael.Sedlmair@visus.uni-stuttgart.de",
    "authors_and_affil": "Frank Heyen (VISUS, University of Stuttgart)*; Quynh Quang Ngo (VISUS, University of Stuttgart); Michael Sedlmair (Uni Stuttgart)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000082.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000082.pdf",
    "position": "3",
    "poster_pdf": "https://drive.google.com/file/d/1w8dCKsqJcsnqocFs_85czyjyKre-gtkJ/view",
    "primary_author": "Frank Heyen",
    "primary_email": "frank.heyen@visus.uni-stuttgart.de",
    "primary_subject": "Musical features and properties -> structure, segmentation, and form",
    "proceedings_id": "82",
    "secondary_subject": "MIR tasks -> pattern matching and detection; MIR tasks -> similarity metrics",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1nyDdRA9G_GKqxqVvd_VAjyZZ6vNasbcyGI5aZX-5Q4A/edit#slide=id.g24dde5fbebb_2_259",
    "thumbnail": "https://drive.google.com/file/d/1eP7DTcz1w1CQzdCdZkDkFWNSRLn8Ppil/view",
    "title": "Visual Overviews for Sheet Music Structure",
    "uid": "216",
    "video": "https://drive.google.com/uc?export=view&id=1QqrLFOACnxQebUM1qdQT2AmCTegxTCmz"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/15qRSYgL-w431GrhVbmHAjeBfhJE2FK2k/view",
    "abstract": "Many applications of cross-modal music retrieval are related to connecting sheet music images to audio recordings. A typical and recent approach to this is to learn, via deep neural networks, a joint embedding space that correlates short fixed-size snippe",
    "abstract_short": "",
    "author_emails": "luis.carvalho@jku.at; gerhard.widmer@jku.at",
    "authors_and_affil": "Luis Carvalho (Johannes Kepler University)*; Gerhard Widmer (Johannes Kepler University)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000083.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000083.pdf",
    "position": "4",
    "poster_pdf": "https://drive.google.com/file/d/16aq0qsq19INHfi84Sin02FuzEjB-Xmtg/view",
    "primary_author": "Luis Carvalho",
    "primary_email": "luis.carvalho@jku.at",
    "primary_subject": "Applications -> music retrieval systems",
    "proceedings_id": "83",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> multimodality; MIR tasks -> indexing and querying; Musical features and properties -> representations of music",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/11QvPMTpdKHgomBbt8AbYQSbKHydqwWZr/view?usp=share_link",
    "thumbnail": "https://drive.google.com/file/d/1RAPcV6AWFbK_fcH4Nhtxo_cCjFeFRmuE/view",
    "title": "Passage Summarization with recurrent models for Audio \u2013 Sheet Music Retrieval",
    "uid": "217",
    "video": "https://drive.google.com/uc?export=view&id=15qRSYgL-w431GrhVbmHAjeBfhJE2FK2k"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1QBmb6yaCFABAGc5IwYkOjqB7PKkCWBLY/view",
    "abstract": "Estimating the performance difficulty of a musical score is crucial in music education for adequately designing the learning curriculum of the students. Although the music information retrieval community has recently shown interest in this task, existing ",
    "abstract_short": "",
    "author_emails": "pedro.ramoneda@upf.edu; dasaemj@sogang.ac.kr; josejavier.valero@upf.edu; xavier.serra@upf.edu",
    "authors_and_affil": "Pedro Ramoneda (Universitat Pompeu Fabra)*; Dasaem Jeong (Sogang University); Jose J. Valero-Mas (Universitat Pompeu Fabra); Xavier Serra (Universitat Pompeu Fabra )",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000084.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000084.pdf",
    "position": "5",
    "poster_pdf": "https://drive.google.com/file/d/1H8IC8Nh5hP1n4RMFKRI_J9sE9-oe50QB/view",
    "primary_author": "Pedro Ramoneda",
    "primary_email": "pedro.ramoneda@upf.edu",
    "primary_subject": "Applications",
    "proceedings_id": "84",
    "secondary_subject": "Applications -> digital libraries and archives; Applications -> music training and education",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1ggbjTinWnjXKdAUtl18jk_x6ZiwNbxp8/edit#slide=id.g1e92513d498_0_7",
    "thumbnail": "https://drive.google.com/file/d/1pyIv2gmhW7ESVie5XjZhA9e4lypN4Idc/view",
    "title": "Predicting performance difficulty from piano sheet music images",
    "uid": "218",
    "video": "https://drive.google.com/uc?export=view&id=1QBmb6yaCFABAGc5IwYkOjqB7PKkCWBLY"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1y4ZGkF2Jlhi-sn4Ci2OnoFTHEm_lshRA/view",
    "abstract": "Music source separation (MSS) faces challenges due to limited availability and potential noise in correctly labeled individual instrument tracks. In this paper, we propose an automated approach for refining mislabeled instrument tracks in a partially nois",
    "abstract_short": "",
    "author_emails": "dg22302@snu.ac.kr; yunkimo95@snu.ac.kr; vinyne@snu.ac.kr; kglee@snu.ac.kr",
    "authors_and_affil": "Junghyun Koo (Seoul National University); Yunkee Chae (Seoul National University)*; Chang-Bin Jeon (Seoul National University); Kyogu Lee (Seoul National University)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000085.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000085.pdf",
    "position": "6",
    "poster_pdf": "https://drive.google.com/file/d/139i9K8i6jx5hs0D6oPwD9gUUuN4XEzpz/view",
    "primary_author": "Yunkee Chae",
    "primary_email": "yunkimo95@snu.ac.kr",
    "primary_subject": "MIR tasks -> automatic classification",
    "proceedings_id": "85",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> annotation protocols; MIR tasks -> sound source separation",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1kL8I5joAX4lUI488J8rrf5ei-5jFXuin/view",
    "thumbnail": "https://drive.google.com/file/d/1wz5TKBDBZF5HXfuJiHr_ouDVLW2xQ9RU/view",
    "title": "Self-Refining of Pseudo Labels for Music Source Separation with Noisy Labeled Data",
    "uid": "288",
    "video": "https://drive.google.com/uc?export=view&id=1y4ZGkF2Jlhi-sn4Ci2OnoFTHEm_lshRA"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/18wnkJGsvsQoydKJCUe1OFNoaK_fS0W35/view",
    "abstract": "Quantifying the difficulty of playing songs has recently gained traction in the MIR community. While previous work has mostly focused on piano, this paper concentrates on rhythm guitar, which is especially popular with amateur musicians and has a broad sk",
    "abstract_short": "",
    "author_emails": "m.a.velezvasquez@uva.nl; m.c.e.baelemans@uva.nl; jonathan@chordify.net; w.h.zuidema@uva.nl; j.a.burgoyne@uva.nl",
    "authors_and_affil": "Marcel A V\u00e9lez V\u00e1squez (University of Amsterdam)*; Mari\u00eblle  Baelemans (University of Amsterdam); Jonathan Driedger (Chordify); Willem Zuidema (ILLC, UvA); John Ashley Burgoyne (University of Amsterdam)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000086.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000086.pdf",
    "position": "7",
    "poster_pdf": "https://drive.google.com/file/d/1sesOh351ItbTXHGgEfFTCQY5U7P4oNg7/view?usp=sharing ",
    "primary_author": "Marcel A V\u00e9lez V\u00e1squez",
    "primary_email": "m.a.velezvasquez@uva.nl",
    "primary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "proceedings_id": "86",
    "secondary_subject": "Applications -> music training and education; Evaluation, datasets, and reproducibility -> annotation protocols; Human-centered MIR -> user-centered evaluation; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Musical features and properties -> harmony, chords and tonality",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1zuttpAiI6ylNAqCUCZcCb4QMBOVaPL74/view",
    "thumbnail": "https://drive.google.com/file/d/1cDyf7XFifNl7ojPkqYTlZhr63H5LuovV/view",
    "title": "Quantifying the Ease of Playing Song Chords on the Guitar",
    "uid": "225",
    "video": "https://drive.google.com/uc?export=view&id=18wnkJGsvsQoydKJCUe1OFNoaK_fS0W35"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1X4iAg6IrkXmFmOODNbJSbq71M-aMlR7H/view",
    "abstract": "Alignment algorithms like DTW and subsequence DTW assume specific boundary conditions on where an alignment path can begin and end in the cost matrix.  In practice, the boundary conditions may not be known a priori or may not satisfy such strict assumptio",
    "abstract_short": "",
    "author_emails": "ibab2018@mymail.pomona.edu; zhangjt@umich.edu; ttsai@g.hmc.edu",
    "authors_and_affil": "Irmak Bukey (Pomona College); Jason Zhang (University of Michigan); Timothy Tsai (Harvey Mudd College)*",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000087.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000087.pdf",
    "position": "8",
    "poster_pdf": "https://drive.google.com/file/d/1qNpxCnv167R5lwPIetpbOveI_VK3QKsh/view",
    "primary_author": "Timothy Tsai",
    "primary_email": "ttsai@g.hmc.edu",
    "primary_subject": "MIR tasks -> alignment, synchronization, and score following",
    "proceedings_id": "87",
    "secondary_subject": "MIR fundamentals and methodology -> music signal processing",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/13QXrP9TfIRAlWXiVj1YfHZJJtOowEInc/view",
    "thumbnail": "https://drive.google.com/file/d/1BN51rFgI2RdzQOar5_fjQ-Ll3Rvqnwwt/view",
    "title": "FlexDTW: Dynamic Time Warping With Flexible Boundary Conditions",
    "uid": "235",
    "video": "https://drive.google.com/uc?export=view&id=1X4iAg6IrkXmFmOODNbJSbq71M-aMlR7H"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1XXZNSayceHF8YHyjGkUCzeF3CHWeNJIs/view",
    "abstract": "Tablature notation is widely used in popular music to transcribe and share guitar musical content. As a complement to standard score notation, tablatures transcribe performance gesture information including finger positions and a variety of guitar-specifi",
    "abstract_short": "",
    "author_emails": "alexandre.dhooge@univ-lille.fr; louis.bigo@univ-lille.fr; ken.deguernel@univ-lille.fr",
    "authors_and_affil": "Alexandre D'Hooge (Universit\u00e9 de Lille)*; Louis Bigo (Universit\u00e9 de Lille); Ken D\u00e9guernel (CNRS)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000088.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000088.pdf",
    "position": "9",
    "poster_pdf": "https://drive.google.com/file/d/1K3KRVVWiVIuj59AeMspoHofr2mAQUCFa/view",
    "primary_author": "Alexandre D'Hooge",
    "primary_email": "alexandre.dhooge@univ-lille.fr",
    "primary_subject": "Knowledge-driven approaches to MIR",
    "proceedings_id": "88",
    "secondary_subject": "Applications -> music composition, performance, and production; MIR fundamentals and methodology -> symbolic music processing; Musical features and properties -> expression and performative aspects of music",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1UGmVpe7pBZ-5D-psux8IYuJoa-c8JeNN/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/1CRKc3eJrIAxxfuM8dnUPP8uWTQC9XibN/view",
    "title": "Modeling Bends in Popular Music Guitar Tablatures",
    "uid": "166",
    "video": "https://drive.google.com/uc?export=view&id=1XXZNSayceHF8YHyjGkUCzeF3CHWeNJIs"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1xqLMnWUj3hT_sjnqvwheaofzbZXjVOzJ/view",
    "abstract": "Music Structure Analysis (MSA) is the task aiming at identifying musical segments that compose a music track and possibly label them based on their similarity. \nIn this paper we propose a supervised approach for the task of music boundary detection. In ou",
    "abstract_short": "",
    "author_emails": "geoffroy.peeters@telecom-paris.fr",
    "authors_and_affil": "Geoffroy Peeters (LTCI - T\u00e9l\u00e9com Paris, IP Paris)*",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000089.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000089.pdf",
    "position": "10",
    "poster_pdf": "https://drive.google.com/file/d/121wH3eycz4zZ9mNNgiw8YeOnAsGmPnAe/view",
    "primary_author": "Geoffroy Peeters",
    "primary_email": "geoffroy.peeters@telecom-paris.fr",
    "primary_subject": "Musical features and properties -> structure, segmentation, and form",
    "proceedings_id": "89",
    "secondary_subject": "MIR fundamentals and methodology -> music signal processing",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1C_GxzKeRASGzV66NXQbG5Z6Vrzk3bQXG/view",
    "thumbnail": "https://drive.google.com/file/d/1PzC9ayjSkxw8Bjpfo5WumSCw27LCT4Qe/view",
    "title": "Self-Similarity-Based and Novelty-based loss for music structure analysis",
    "uid": "279",
    "video": "https://drive.google.com/uc?export=view&id=1xqLMnWUj3hT_sjnqvwheaofzbZXjVOzJ"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1lNhHbatsqrN-i2u-FddjD2ziHofHHhCg/view",
    "abstract": "In jazz, measuring harmonic similarity is complicated by the common practice of reharmonization -- the altering or substitution of chords without fundamentally changing the piece's harmonic identity. This is analogous to natural language processing tasks ",
    "abstract_short": "",
    "author_emails": "c.bunks@qmul.ac.uk; s.e.dixon@qmul.ac.uk; t.e.weyde@city.ac.uk; bdigiorgi@apple.com",
    "authors_and_affil": "Carey Bunks (City, University London)*; Simon Dixon (Queen Mary University of London); Tillman Weyde (City, University of London); Bruno Di Giorgi (Apple)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000090.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000090.pdf",
    "position": "11",
    "poster_pdf": "https://drive.google.com/file/d/1ciE5bkv_nwm_kw_WaV6GLaqgN3gPT1JG/view",
    "primary_author": "Carey Bunks",
    "primary_email": "c.bunks@qmul.ac.uk",
    "primary_subject": "Musical features and properties -> representations of music",
    "proceedings_id": "90",
    "secondary_subject": "MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> similarity metrics; Musical features and properties -> harmony, chords and tonality",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1_jthEKwcX8fB0q662jv0SMGg_jj5wIB8/view",
    "thumbnail": "https://drive.google.com/file/d/1DrWsujLUQNd6LlP-WwBq1SMYX-lvV7qd/view",
    "title": "Modeling Harmonic Similarity for Jazz Using Co-occurrence Vectors and the Membrane Area",
    "uid": "239",
    "video": "https://drive.google.com/uc?export=view&id=1lNhHbatsqrN-i2u-FddjD2ziHofHHhCg"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1zUOje_v-rxU2buZJAE78g0UeOoZu8aex/view",
    "abstract": "There has been a persistent lack of publicly accessible data in singing voice research, particularly concerning the diversity of languages and performance styles. In this paper, we introduce SingStyle111, a large studio-quality singing dataset with multip",
    "abstract_short": "",
    "author_emails": "shuqid@cs.cmu.edu; schen307@usc.edu; yuxuanw2@andrew.cmu.edu; rghuang@andrew.cmu.edu; rbd@cs.cmu.edu",
    "authors_and_affil": "Shuqi Dai (Carnegie Mellon University)*; Siqi Chen (University of South California); Yuxuan Wu (Carnegie Mellon University); Roy Huang (Carnegie Mellon University); Roger B. Dannenberg (School of Computer Science, Carnegie Mellon University)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000091.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000091.pdf",
    "position": "12",
    "poster_pdf": "",
    "primary_author": "Shuqi Dai",
    "primary_email": "shuqid@cs.cmu.edu",
    "primary_subject": "Evaluation, datasets, and reproducibility",
    "proceedings_id": "91",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://docs.google.com/presentation/d/1tdEBfkCBUr5rp47yxtelZuxUtwdY0aJC/edit?usp=share_link&ouid=116278840554580538889&rtpof=true&sd=true",
    "thumbnail": "https://drive.google.com/file/d/162X-YscQ5gJDBkLRCsHHhfmXBoxs9c_y/view",
    "title": "SingStyle111: A Multilingual Singing Dataset With Style Transfer",
    "uid": "25",
    "video": "https://drive.google.com/uc?export=view&id=1zUOje_v-rxU2buZJAE78g0UeOoZu8aex"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1u2Zp6skZxD3j5rwmlFHi_D1JkQKcDifA/view",
    "abstract": "Lyric translation plays a pivotal role in amplifying the global resonance of music, bridging cultural divides, and fostering universal connections. Translating lyrics, unlike conventional translation tasks, requires a delicate balance between singability ",
    "abstract_short": "",
    "author_emails": "khaven@kaist.ac.kr; kento.watanabe@aist.go.jp; m.goto@aist.go.jp; juhan.nam@kaist.ac.kr",
    "authors_and_affil": "Haven Kim (KAIST)*; Kento Watanabe (National Institute of Advanced Industrial Science and Technology (AIST)); Masataka Goto (National Institute of Advanced Industrial Science and Technology (AIST)); Juhan Nam (KAIST)",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000092.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000092.pdf",
    "position": "13",
    "poster_pdf": "https://drive.google.com/file/d/13EbuMQL3bXnAMgI9Rjm37m0_u4Npg8VC/view",
    "primary_author": "Haven Kim",
    "primary_email": "khaven@kaist.ac.kr",
    "primary_subject": "MIR fundamentals and methodology -> lyrics and other textual data",
    "proceedings_id": "92",
    "secondary_subject": "Computational musicology; Evaluation, datasets, and reproducibility; Evaluation, datasets, and reproducibility -> evaluation methodology; Evaluation, datasets, and reproducibility -> evaluation metrics; MIR fundamentals and methodology -> web mining, and natural language processing",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1Q4KYujFVZN08NpdPsjNVLDNk5wp5sXJ_/view",
    "thumbnail": "https://drive.google.com/file/d/1bsNIzDKIKvA3XDvcrXjhLr8UiYlhuATe/view",
    "title": "A Computational Evaluation Framework for Singable Lyric Translation",
    "uid": "255",
    "video": "https://drive.google.com/uc?export=view&id=1u2Zp6skZxD3j5rwmlFHi_D1JkQKcDifA"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1Yg9P6EWBZlriwOMFyjsR268Y7X5waAGn/view",
    "abstract": "When people listen to playlists on a music streaming service, they typically listen to each song from start to end in order. However, what if it were possible to use a function to listen to only the choruses of each song in a playlist one after another? I",
    "abstract_short": "",
    "author_emails": "k.tsukuda@aist.go.jp; masahiro.hamasaki@aist.go.jp; m.goto@aist.go.jp",
    "authors_and_affil": "Kosetsu Tsukuda (National Institute of Advanced Industrial Science and Technology (AIST))*; Masahiro Hamasaki (National Institute of Advanced Industrial Science and Technology (AIST)); Masataka Goto (National Institute of Advanced Industrial Science and T",
    "channel_url": "",
    "day": "4",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000093.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000093.pdf",
    "position": "14",
    "poster_pdf": "https://drive.google.com/file/d/1D_S3hsdk6Gd_ypaU1QNEIZUYZ5J1F-nn/view",
    "primary_author": "Kosetsu Tsukuda",
    "primary_email": "k.tsukuda@aist.go.jp",
    "primary_subject": "Human-centered MIR -> human-computer interaction",
    "proceedings_id": "93",
    "secondary_subject": "Human-centered MIR -> music interfaces and services",
    "session": "6",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1gYyQWnAkIZXf9mnDPVY43dTd0jyF-RhD/view",
    "thumbnail": "https://drive.google.com/file/d/1a7HsyxwthWwKit7Ukc0ZFxF2onE1pY_9/view",
    "title": "Chorus-Playlist: Exploring the Impact of Listening to Only Choruses in a Playlist",
    "uid": "257",
    "video": "https://drive.google.com/uc?export=view&id=1Yg9P6EWBZlriwOMFyjsR268Y7X5waAGn"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1hhHR2gBnuA_U-ur1la-5g_Gdjigaj-IA/view",
    "abstract": "Digital musicology research often proceeds by extending and enriching its evidence base as it progresses, rather than starting with a complete corpus of data and metadata, as a consequence of an emergent research need.\n\nIn this paper, we consider a resear",
    "abstract_short": "",
    "author_emails": "david.lewis@oerc.ox.ac.uk; shibata@beethoven.de; andrew.hankinson@rism.digital; kepper@edirom.de; kevin.page@oerc.ox.ac.uk; lisarosendahl@gmx.com; mark.saccomano@uni-paderborn.de; siegert@beethoven.de",
    "authors_and_affil": "David Lewis (University of Oxford eResearch Centre)*; Elisabete Shibata (Beethoven-Haus Bonn); Andrew Hankinson (RISM Digital); Johannes Kepper (Paderborn University); Kevin R Page (University of Oxford); Lisa Rosendahl (Paderborn University); Mark Saccom",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000094.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000094.pdf",
    "position": "0",
    "poster_pdf": "https://drive.google.com/file/d/1SfhuAl2LxICb6Tqh9VHB4MhrkLYy7LXZ/view",
    "primary_author": "David Lewis",
    "primary_email": "david.lewis@oerc.ox.ac.uk",
    "primary_subject": "Computational musicology -> digital musicology",
    "proceedings_id": "94",
    "secondary_subject": "Applications -> digital libraries and archives; Evaluation, datasets, and reproducibility -> annotation protocols; Human-centered MIR -> music interfaces and services; MIR fundamentals and methodology -> metadata, tags, linked data, and semantic web",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1L695BRLMbAvPgZ2diOXLIpC10fzt42Ar/view",
    "thumbnail": "https://drive.google.com/file/d/1TJAiDOT_z9XkW0iAvJiyOyO6otFfN__i/view",
    "title": "Supporting musicological investigations with information retrieval tools: an iterative approach to data collection",
    "uid": "172",
    "video": "https://drive.google.com/uc?export=view&id=1hhHR2gBnuA_U-ur1la-5g_Gdjigaj-IA"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1O6IL5DwvLC1w389b5agKpwZG-c8kTz8N/view",
    "abstract": "This paper presents a comprehensive investigation of existing feature extraction tools for symbolic music and contrasts their performance to determine the set of features that best characterizes the musical style of a given music score. In this regard, we",
    "abstract_short": "",
    "author_emails": "fsimonetta@iccmu.es; allorens@ucm.es; mserrano@iccmu.es; edgarcia@est-econ.uc3m.es; atorrente@iccmu.es",
    "authors_and_affil": "Federico Simonetta (Instituto Complutense de Ciencias Musicales)*; Ana Llorens (Universidad Complutense de Madrid); Mart\u00edn Serrano (Instituto Complutense de Ciencias Musicales); Eduardo Garc\u00eda-Portugu\u00e9s (Universidad Carlos III de Madrid); \u00c1lvaro Torrente ",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000095.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000095.pdf",
    "position": "1",
    "poster_pdf": "https://drive.google.com/file/d/1pMp8Jvp4vA8rIN2SrAmF8-9sXIpOnGiO/view",
    "primary_author": "Federico Simonetta",
    "primary_email": "fsimonetta@iccmu.es",
    "primary_subject": "Computational musicology",
    "proceedings_id": "95",
    "secondary_subject": "Computational musicology -> systematic musicology; Knowledge-driven approaches to MIR -> computational music theory and musicology; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR fundamentals and methodology -> symbolic music processing; Musical features and properties",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1_w78MiJSAvgTVFKZu0bbGxDpaaMWzpA5/view",
    "thumbnail": "https://drive.google.com/file/d/1opJZYW_qoczWG31bwyX_A-xMhutI0V8g/view",
    "title": "Optimizing Feature Extraction for Symbolic Music",
    "uid": "96",
    "video": "https://drive.google.com/uc?export=view&id=1O6IL5DwvLC1w389b5agKpwZG-c8kTz8N"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1F_A6d1BGTWa4n-v1osN5z9gROll7r5Lj/view",
    "abstract": "Research in natural language processing has demonstrated that the quality of generations from trained autoregressive language models is significantly influenced by the used sampling strategy. In this study, we investigate the impact of different sampling ",
    "abstract_short": "",
    "author_emails": "muthissar@gmail.com; stefan.lattner@sony.com; gerhard.widmer@jku.at",
    "authors_and_affil": "Mathias Rose Bjare (Johannes Kepler University Linz)*; Stefan Lattner (Sony CSL); Gerhard Widmer (Johannes Kepler University)",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000096.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000096.pdf",
    "position": "2",
    "poster_pdf": "https://drive.google.com/file/d/1_ZolJIkB1I7G0S5K_-DsqR7_-9MnWtfa/view",
    "primary_author": "Mathias Rose Bjare",
    "primary_email": "muthissar@gmail.com",
    "primary_subject": "MIR tasks -> music generation",
    "proceedings_id": "96",
    "secondary_subject": "Applications -> music composition, performance, and production; MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> music synthesis and transformation; Musical features and properties -> melody and motives; Musical features and properties -> structure, segmentation, and form",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1-aIfAI9BtIWCBerw08HPK9qU3OZqGoy2/view",
    "thumbnail": "https://drive.google.com/file/d/1rbDRvHNLeKUN7NvnFjCaU6HU6b3HRFZz/view",
    "title": "Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model",
    "uid": "274",
    "video": "https://drive.google.com/uc?export=view&id=1F_A6d1BGTWa4n-v1osN5z9gROll7r5Lj"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "",
    "abstract": "Every year, several dozen, primarily European, countries, send performers to compete on live television at the Eurovision Song Contest, with the goal of entertaining an international audience of more than 150 million viewers. Each participating country is",
    "abstract_short": "",
    "author_emails": "j.a.burgoyne@uva.nl; janne.spijkervet@gmail.com; d.j.baker@uva.nl",
    "authors_and_affil": "John Ashley Burgoyne (University of Amsterdam)*; Janne Spijkervet (University of Amsterdam); David J Baker (University of Amsterdam)",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000097.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000097.pdf",
    "position": "3",
    "poster_pdf": "",
    "primary_author": "John Ashley Burgoyne",
    "primary_email": "j.a.burgoyne@uva.nl",
    "primary_subject": "Evaluation, datasets, and reproducibility -> novel datasets and use cases",
    "proceedings_id": "97",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> evaluation metrics; Human-centered MIR -> user behavior analysis and mining, user modeling; Knowledge-driven approaches to MIR -> computational ethnomusicology; MIR fundamentals and methodology -> metadata, tags, linked data, and semantic web; Musical features and properties -> expression and performative aspects of music",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "",
    "thumbnail": "",
    "title": "Measuring the Eurovision Song Contest: A Living Dataset for Real-World MIR",
    "uid": "276",
    "video": ""
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1pYJ_xgEA1kqqYQ9WvqzVPHnRewmz-hzJ/view",
    "abstract": "In this work, we address music representation learning using convolution-free transformers. We build on top of existing spectrogram-based audio transformers such as AST and train our models on a supervised task using patchout training similar to PaSST. In",
    "abstract_short": "",
    "author_emails": "pablo.alonso@upf.edu; xavier.serra@upf.edu; dmitry.bogdanov@upf.edu",
    "authors_and_affil": "Pablo Alonso-Jim\u00e9nez (Universitat Pompeu Fabra)*; Xavier Serra (Universitat Pompeu Fabra ); Dmitry Bogdanov (Universitat Pompeu Fabra)",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000098.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000098.pdf",
    "position": "4",
    "poster_pdf": "https://drive.google.com/file/d/1RSGNN1xzfXuzyjHy1ZIkWmUWF8qOS-Ml/view",
    "primary_author": "Pablo Alonso-Jim\u00e9nez",
    "primary_email": "pablo.alonso@upf.edu",
    "primary_subject": "Musical features and properties -> representations of music",
    "proceedings_id": "98",
    "secondary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; MIR tasks -> automatic classification; Musical features and properties -> musical affect, emotion and mood; Musical features and properties -> musical style and genre; Musical features and properties -> timbre, instrumentation, and singing voice",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1RI6H4LsGvtfPitec9A_tbIU3F1CPzMjY/view",
    "thumbnail": "https://drive.google.com/file/d/1OfoD4hN9VyyTdAfWv0mFF8gIZfUteVNU/view",
    "title": "Efficient Supervised Training of Audio Transformers for Music Representation Learning",
    "uid": "248",
    "video": "https://drive.google.com/uc?export=view&id=1pYJ_xgEA1kqqYQ9WvqzVPHnRewmz-hzJ"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1m4gubvlJ3XO25aLLlSbhY3_O7c960PXe/view",
    "abstract": "Deep learning systems have become popular for tackling a variety of music information retrieval tasks. However, these systems often require large amounts of labeled data for supervised training, which can be very costly to obtain. To alleviate this proble",
    "abstract_short": "",
    "author_emails": "michael.krause@audiolabs-erlangen.de; christof.weiss@uni-wuerzburg.de; meinard.mueller@audiolabs-erlangen.de",
    "authors_and_affil": "Michael Krause (International Audio Laboratories Erlangen)*; Christof Wei\u00df (University of W\u00fcrzburg); Meinard M\u00fcller (International Audio Laboratories Erlangen)",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000099.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000099.pdf",
    "position": "5",
    "poster_pdf": "https://drive.google.com/file/d/116v-81IMZNYlMz551ahs-D7xmnKdCvkn/view",
    "primary_author": "Michael Krause",
    "primary_email": "michael.krause@audiolabs-erlangen.de",
    "primary_subject": "Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music",
    "proceedings_id": "99",
    "secondary_subject": "MIR tasks -> similarity metrics; Musical features and properties -> representations of music; Musical features and properties -> timbre, instrumentation, and singing voice",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1abOekT3Z5IB-9UpyKZLm9iZj7NuxHwxD/view",
    "thumbnail": "https://drive.google.com/file/d/17lmKrbUhR_PxD6RwdUpKmqRLcSvWShDt/view",
    "title": "A Cross-Version Approach to Audio Representation Learning for Orchestral Music",
    "uid": "79",
    "video": "https://drive.google.com/uc?export=view&id=1m4gubvlJ3XO25aLLlSbhY3_O7c960PXe"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1OdDDCEu0TnAWs0wi2vAtTGRm5pAodRN4/view",
    "abstract": "This paper proposes a new music source separation (MSS) model based on an architecture with MLP-Mixer that leverages multilayer perceptrons (MLPs). Most of the recent MSS techniques are based on architectures with CNNs, RNNs, and attention-based transform",
    "abstract_short": "",
    "author_emails": "t.nakano@aist.go.jp; m.goto@aist.go.jp",
    "authors_and_affil": "Tomoyasu Nakano (National Institute of Advanced Industrial Science and Technology (AIST))*; Masataka Goto (National Institute of Advanced Industrial Science and Technology (AIST))",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000100.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000100.pdf",
    "position": "6",
    "poster_pdf": "https://drive.google.com/file/d/1pVSndiIoUYLscD295HxipgYLpldiJ56i/view",
    "primary_author": "Tomoyasu Nakano",
    "primary_email": "t.nakano@aist.go.jp",
    "primary_subject": "MIR tasks -> sound source separation",
    "proceedings_id": "100",
    "secondary_subject": "MIR fundamentals and methodology -> music signal processing",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1mUCXimBtROHSKFznac8FlM727Uf-Kb5g/view",
    "thumbnail": "https://drive.google.com/file/d/1x1nOic95F0W6ASQHRd0avta3_U209gEY/view",
    "title": "Music source separation with MLP mixing of time, frequency, and channel",
    "uid": "278",
    "video": "https://drive.google.com/uc?export=view&id=1OdDDCEu0TnAWs0wi2vAtTGRm5pAodRN4"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1uMhKpUkVAiNaaUTFoFzAhxOQZBsHnu4Z/view",
    "abstract": "Music Information Retrieval (MIR) has seen a recent surge in deep learning-based approaches, which often involve encoding symbolic music (i.e., music represented in terms of discrete note events) in an image-like or language-like fashion. However, symboli",
    "abstract_short": "",
    "author_emails": "huan.zhang@qmul.ac.uk; emmanouil.karystinaios@jku.at; s.e.dixon@qmul.ac.uk; gerhard.widmer@jku.at; carlos_eduardo.cancino_chacon@jku.at",
    "authors_and_affil": "Huan Zhang (Queen Mary University of London)*; Emmanouil Karystinaios (Johannes Kepler University); Simon Dixon (Queen Mary University of London); Gerhard Widmer (Johannes Kepler University); Carlos Eduardo Cancino-Chac\u00f3n (Johannes Kepler University Linz)",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "Virtually",
    "pdf_name": "000101.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000101.pdf",
    "position": "7",
    "poster_pdf": "https://drive.google.com/file/d/1_57q-qGsRO9druNfRi3YHndX4LqLll4r/view",
    "primary_author": "Huan Zhang",
    "primary_email": "huan.zhang@qmul.ac.uk",
    "primary_subject": "MIR fundamentals and methodology -> symbolic music processing",
    "proceedings_id": "101",
    "secondary_subject": "Evaluation, datasets, and reproducibility -> evaluation methodology; Knowledge-driven approaches to MIR -> machine learning/artificial intelligence for music; Knowledge-driven approaches to MIR -> representations of music; MIR tasks -> automatic classification; Musical features and properties -> representations of music",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1Xfrdwc4P-oI5bzz9g_SrJchCwqu09dvo/view",
    "thumbnail": "https://drive.google.com/file/d/1Drbq0ENSx89p_s9JtB9LDo7ITkDV8hkT/view",
    "title": "Symbolic Music Representations for Classification Tasks: A Systematic Evaluation",
    "uid": "54",
    "video": "https://drive.google.com/uc?export=view&id=1uMhKpUkVAiNaaUTFoFzAhxOQZBsHnu4Z"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1sWmDSmjUDTcma5qxam4u_qSe1tQZXY6K/view",
    "abstract": "The semantic description of music metadata is a key requirement for the creation of music datasets that can be aligned, integrated, and accessed for information retrieval and knowledge discovery. It is nonetheless an open challenge due to the complexity o",
    "abstract_short": "",
    "author_emails": "valentina.carriero3@unibo.it; jacopo.deberardinis@kcl.ac.uk; albert.merono@kcl.ac.uk; andrea.poltronieri2@unibo.it; valentina.presutti@unibo.it",
    "authors_and_affil": "Valentina Carriero (University of Bologna); Jacopo de Berardinis (King's College London); Albert Mero\u00f1o-Pe\u00f1uela (King's College London); Andrea Poltronieri (University of Bologna)*; Valentina Presutti (University of Bologna)",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000102.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000102.pdf",
    "position": "8",
    "poster_pdf": "https://drive.google.com/file/d/1lJSkNd_OzlU73QswUv1Ca93O_UY4BA-c/view",
    "primary_author": "Andrea Poltronieri",
    "primary_email": "andrea.poltronieri2@unibo.it",
    "primary_subject": "MIR fundamentals and methodology -> metadata, tags, linked data, and semantic web",
    "proceedings_id": "102",
    "secondary_subject": "Applications -> digital libraries and archives; Knowledge-driven approaches to MIR -> representations of music",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1fIylHtuJBQX1X1wnIvR0oInoxBE0lvpq/view",
    "thumbnail": "https://drive.google.com/file/d/1BjDSWYba5EKYc3zxqWTFJdMroDD7OWVm/view",
    "title": "The Music Meta Ontology: a flexible semantic model for the interoperability of music metadata",
    "uid": "283",
    "video": "https://drive.google.com/uc?export=view&id=1sWmDSmjUDTcma5qxam4u_qSe1tQZXY6K"
  },
  {
    "AwardNominee": "False",
    "SpecialTrack": "",
    "StudentAuthor": "",
    "Video Link": "https://drive.google.com/file/d/1wRsgtl_jBL20Cm317Yp1879UHKs7-d5b/view",
    "abstract": "Large-scale studies of musical harmony are often hampered by lack of suitably labelled data. It would be highly advantageous if an algorithm were able to autonomously describe chords, scales, etc. in a consistent and musically informative way. In this pap",
    "abstract_short": "",
    "author_emails": "j.k.miller@qmul.ac.uk; j.pauwels@qmul.ac.uk; mark.sandler@qmul.ac.uk",
    "authors_and_affil": "Jeffrey K Miller (Queen Mary University of London)*; Johan Pauwels (Queen Mary University of London); Mark B Sandler (Queen Mary University of London)",
    "channel_url": "",
    "day": "5",
    "long_presentation": "False",
    "paper_presentation": "In Person",
    "pdf_name": "000103.pdf",
    "pdf_path": "https://archives.ismir.net/ismir2023/paper/000103.pdf",
    "position": "9",
    "poster_pdf": "https://drive.google.com/file/d/1BdVT7RIJJIrCPVhUBL5JoFYJHoUjzZWd/view",
    "primary_author": "Jeffrey K Miller",
    "primary_email": "j.k.miller@qmul.ac.uk",
    "primary_subject": "Knowledge-driven approaches to MIR -> computational music theory and musicology",
    "proceedings_id": "103",
    "secondary_subject": "Computational musicology -> mathematical music theory; Knowledge-driven approaches to MIR -> representations of music; MIR fundamentals and methodology -> symbolic music processing; MIR tasks -> similarity metrics; Musical features and properties -> harmony, chords and tonality",
    "session": "7",
    "slack_channel": "",
    "slides_pdf": "https://drive.google.com/file/d/1gSLS95kXdT7yw8oneBF16E_FOduR36h5/view",
    "thumbnail": "https://drive.google.com/file/d/1zJyH-rDZuVL4AdIP8p25WRbLLtizMkEf/view",
    "title": "Polar Manhattan Displacement: measuring tonal distances between chords based on intervallic content",
    "uid": "294",
    "video": "https://drive.google.com/uc?export=view&id=1wRsgtl_jBL20Cm317Yp1879UHKs7-d5b"
  }
]
